<doc>
  <source auto="true" type="str" verify="true"><![CDATA[https://cyberleninka.ru/article/n/vozmozhnosti-ispolzovaniya-graficheskogo-akseleratora-dlya-realizatsii-neyrosetevyh-algoritmov]]></source>
  <category auto="true" type="str" verify="true"><![CDATA[Автоматика]]></category>
  <author auto="true" type="list" verify="true">
    <item type="str"><![CDATA[Гузик В.Ф.]]></item>
    <item type="str"><![CDATA[Чернухин Ю.В.]]></item>
    <item type="str"><![CDATA[Десятерик М.Н.]]></item>
  </author>
  <title auto="true" type="str" verify="true"><![CDATA[Возможности использования графического акселератора для реализации нейросетевых алгоритмов]]></title>
  <keywords auto="true" type="list" verify="true">
    <item type="str"><![CDATA[НЕЙРОСЕТИ]]></item>
    <item type="str"><![CDATA[КЛАССИФИКАЦИЯ]]></item>
    <item type="str"><![CDATA[ОБУЧЕНИЕ]]></item>
    <item type="str"><![CDATA[ШЕЙДЕР]]></item>
  </keywords>
  <annotation auto="true" type="str" verify="true"><![CDATA[Работа посвящена исследованию возможности реализации нейросетевых алгоритмов на базе графических акселераторов (GPU), основным принципам реализации алгоритмов классификации на основе многопроцессорных систем. Описывается методика применения разработанных алгоритмов при реализации алгоритма классификации для многослойных нейросетей большой размерности.]]></annotation>
  <text auto="true" type="str" verify="true"><![CDATA[В последнее время нейросетевой подход к решению различного рода прикладных задач получает все большую популярность. Однако алгоритмы классификации и обучения нейросетей требуют существенных вычислительных мощностей. В настоящее время существует набор аппаратных решений, позволяющих увеличить скорость обучения нейросетей и выполнения процедуры классификации за счет распараллеливания нейросетевых алгоритмов на нескольких процессорах. Например, компания NVidia предлагает аппаратный комплекс Tesla C870 состоящий из 128 процессоров с общей производительностью 518 гигафлоп, Tesla D870 (256 процессоров, 1 терафлоп), Tesla S870 (512 процессоров, 2 терафлоп). Однако стоимость этих устройств довольно высока и составляет 1500, 7500, и 12000 USD соответственно [1]. В то же время любой современный компьютер оборудован графическим ускорителем, являющимся многопроцессорной системой, и способной выполнять пользовательские программы (шейдеры) параллельно, что также может быть использовано при практической реализации нейросетевых алгоритмов. Например, видеокарта ATI Radeon HD 2900 XT, построенная на базе графического чипа RV630, содержит 120 унифицированных графических процессоров, с общей производительностью 475 гигафлоп и стоимостью всего 400 USD. Для сравнения можно сказать, что четырёхпроцессорная система на базе двуядерных чипов Intel Itanium 2 (Montecito) обеспечивает производительность всего порядка 45 гигафлоп[2]. Отмеченные обстоятельства стимулируют исследование возможности применения современных графических акселераторов (Graphic Processor Unit, GPU) в нейросетевой технике. Типовая архитектура современных GPU Современный графический акселератор, поддерживающий версию шейдеров 3.0, позволяет выполнять шейдеры двух типов: • вершинные шейдеры; • пиксельные шейдеры; Вершинный шейдер - это программа, предназначенная для обработки одной вершины (вертекса). При формировании изображения каждый вертекс проходит заданную пользователем обработку, в процессе которой могут выполняться преобразование координат (применение мировой, видовой и проекционной матриц) вершины, расчет освещения, генерация текстурных координат и т.п. (рис. 1). Рис. 1. Выполнение вершинного шейдера После выполнения вершинного шейдера выполняется этап растеризации, в процессе которого, треугольники делятся на фрагменты (пиксели), для которых интерполируются текстурные координаты и цвет. В результате растеризации, полученный фрагмент помещается в буфер кадра, который является целевым объектом рендеринга (render target). На этапе растеризации выполняется пиксельный шейдер (рис. 2). Пиксельный шейдер - это программа, предназначенная для расчета цвета пиксела (задаваемого в координатах целевого объекта рендеринга) в процессе растеризации изображения. Рис. 2. Пикселный шейдер Код программы (шейдера) выполняется графическим акселератором параллельно (как вершинного, так и пикселного), степень параллелизма зависит от аппаратной архитектуры графического акселератора. Для достижения сложных графических эффектов часто используют несколько шейдеров, выполняемых последовательно, каждый из которых реализует требуемый визуальный эффект, например, отражение объектов, наложение бликов, эффектов тумана, дождя и т.п. (рис. 3,а). При этом прослеживается аналогия по отношению к расчету состояния многослойных нейросетей, когда для расчета состояния нейросети также последовательно выполняется расчет состояний каждого слоя нейросети (рис. 3,б). а б Рис. 3. Последовательное применение шейдеров (а) и расчет состояния нейросети (б) Таким образом, становится возможным применение современных способов формирования графических изображений на основе GPU для расчета состояния многослойных нейросетей и реализации нейросетевых алгоритмов с применением шейдеров. При таком подходе можно рассчитывать состояние одного слоя нейросети за один кадр генерации изображения, при этом, каждый нейрон слоя нейросети будет моделироваться пикселом формируемого изображения, а пиксельный шейдер будет реализовывать активационную функцию нейрона. Вершинный шейдер при том никакой смысловой нагрузки не несет (так как не требуется выполнять какую-либо предварительную модификацию классифицируемого вектора), но должен быть формально реализован. Реализация алгоритма классификации на GPU Для того чтобы заставить графический акселератор выполнить рендеринг кадра, необходимо наполнить список объектов рендеринга графическими примитивами - для этого достаточно формально сформировать сцену, состоящую из двух треугольников покрывающих 2D-пространство с координатами (0,0), (1,1) путем вызова функции DirectX DrawPrimitiveUP. При программировании шейдеров для графической подсистемы DirectX используется язык программирования High Level Shading Language (HLSL). Всю реализацию нейросетевого алгоритма классификации предлагается реализовать на базе пикселного шейдера. При этом достаточно создать вершинный шейдер, не выполняющий никаких преобразований над вертексами: struct VS_OUTPUT { float4 Position : POSITION; float3 TextCoord : TEXCOORDO; }; VS_OUTPUT ShaderFunc(float4 Pos : POSITION) { VS_OUTPUT Out = (VS_OUTPUT)0; Pos.w = 1.0f; Out.Position = Pos; Out.TextCoord = Pos; return Out; } После применения вершинного шейдера, графический акселератор начинает выполнять код пикселного шейдера для каждого пиксела целевого объекта рендеринга. При этом код шейдера, выполняемый графическим акселератором для каждого пиксела целевого объекта рендеринга, реализует заданную активационную функцию нейрона. Данный факт накладывает следующее ограничение на организацию архитектуры нейросети - активационная функция каждого нейрона слоя нейросети должна быть одинаковой в пределах нейросетевого слоя. Практически, существует возможность реализации уникальной активационной функции для каждого нейрона в слое, путем задания дополнительной управляющей текстуры, значение элементов которой (текселов) будет трактоваться шейдером как тип активационной функции каждого нейрона в слое (пороговая, логистическая, и т.п.). Однако такой подход не рекомендуется к применению, так как он требует организации ветвлений в коде шейдера (логических условий и переходов), что негативно сказывается на производительности шейдера. Более того, типовые схемы построения многослойных нейросетей подразумевают наличие нейронов с одинаковой активационной функцией в пределах одного слоя нейросети [3]. Для реализации алгоритмов классификации на основе классического многослойного перцептрона необходимо обеспечить представление следующих структур данных: • набор входных значений каждого слоя нейронов Xik ={,•••,хм 1,-,X1N,•••,XMN}, где M - число входов нейрона в слое, N - число нейронов в слое; • набор весовых коэффициентов для каждого нейрона в слое Wik ={iv, wM1,..., w1NwMN }, где M - число входов нейрона в слое, N - число нейронов в слое; • набор значений выходов нейронов Yk = {y i,..., yN }, где N - число нейронов в слое. При этом, значения выходов Y нейронов k-го слоя будут являться входами X для нейронов k+1 слоя. Команды пикселного шейдера не могут обращаться к данным, расположенным непосредственно в оперативной памяти компьютера - в качестве исходных данных пикселный шейдер может обращаться только к текстурам, значения элементов которых (тексели) трактуются GPU по разному. При применении типа данных D3DFMT_R32F можно заставить GPU трактовать элементы текстуры в виде вещественных чисел одинарной точности. Тогда можно представить внутреннее состояние нейросети с помощью вышеперечисленных структур данных в виде 20-текстур (пример для двухслойной нейросети приведен на рис. 4). ^21 1^22 ^2ЛІ М>М\ Wn.fl УУмк Рис. 4. Представление состояния нейросети в виде текстур В процессе выполнения рендеринга удобно трактовать каждый пиксел целевого объекта рендеринга как один нейрон слоя, при этом за один кадр можно рассчитать значение выходов всех нейронов в пределах одного слоя нейросети. Для расчета многослойных нейросетей достаточно выполнить рендеринг Ь кадров, где Ь - число слоев нейросети. Тогда для пикселного шейдера исходными данными будут являться: • текстура X входных значений нейронов; • текстура Ж весовых коэффициентов входов нейронов. Целевым объектом рендеринга будет являться текстура У, заполняемая рассчитанными значениями выходов нейронов. Таким образом, графический акселератор выполняет код шейдера для каждого пиксела целевого объекта рендеринга, который в данном случае вычисляет значение выхода нейрона У на основе заданной активационной функции с учетом входных значение нейрона X и весовых коэффициентов Ж, значения которых передаются в шейдер в виде текстур. Результат выполнения рендеринга представляется также в виде текстуры У (рис. 5). wn W21 . . . WM1 W12 W22 • . . WM2 . . . W1NiW2N WMN, Рис. 5. Расчет состояния нейронов слоя нейросети Например, для слоя нейросети, каждый нейрон которой имеет по два входа и реализует логистическую активационную функцию, получим следующий текст пикселного шейдера: float4 Steps : register(c0); float4 Offsets : register(c1); sampler2D WTexture : register(s1); sampler2D XTexture : register(s3); struct PS_INPUT { float4 Position : POSITION; float3 TextCoord : TEXCOORD0; float2 vPos : VPOS; }; float4 PixelSh(PS_INPUT Vertex):COLOR0 { const float MaxNet = 45; int i = 0; float2 WPos = {Offsets.x, Vertex.vPos.x*Steps.z + Offsets.z}; float2 XPos = {Offsets.x, Vertex.vPos.y*Steps.y + Offsets.y}; float sum = 0; sum = sum + tex2D(XTexture, XPos)*tex2D(WTexture, WPos); XPos.x = XPos.x + Steps.x; WPos.x = WPos.x + Steps.x; sum = sum + tex2D(XTexture, XPos)*tex2D(WTexture, WPos); XPos.x = XPos.x + Steps.x; WPos.x = WPos.x + Steps.x; sum = clamp(sum, -MaxNet, MaxNet); sum = 1 + exp(-sum); sum = sum*sum; sum = rsqrt(sum); return float4(sum,0,0,0); } Следует обратить внимание на то, что текст пикселного шейдера может генерироваться программой динамически и компилироваться с помощью функции D3DXCompileShader, что позволяет создавать пикселные шейдеры “на лету” для практически любой конфигурации нейросети. Одним из важных ограничений, накладываемых на пикселные шейдеры является то, что большинство современных видеокарт позволяют работать с текстурами размером не более 4096 пикселов по каждому размерению (по ширине или высоте). Исходя из этого ограничения следует, что предложенная схема представления внутреннего состояния нейросети (рис. 4) позволяет выполнять процедуру классификации для нейросетей, где число нейронов в каждом слое не превышает 4096. Данное ограничение может быть снято за счет усложнения представления внутреннего состояния нейросети и пиксел-ного шейдера. Сравнительный анализ быстродействия нейросетевого алгоритма классификации на базе СРи и вРИ проводился для однослойной нейросети с размерностью классифицируемого вектора в 1000 элементов одинарной точности и варьируемым числом нейронов в слое. Проведенные эксперименты показывают, что графический акселератор (вРИ) не всегда обладает превосходством над СРИ по быстродействию (рис. 6). Для использованной аппаратной конфигурации баланс производительности наступает для порядка 45 000 связей (45 нейронов х 1000 входов) в слое. ATI Radeon HD 2600 ХТ vs Intel*R» Core(TM»2 CPU 6320 @ 1.86GHz 1 1 \ы 20 40 60 80 100 Рис. 6. Быстродействие СРП и ОРП для нейросетей небольшой размерности Для нейросетей большой размерности, порядка 106 связей в слое (1000 нейронов х 1000 входов), выигрыш производительности достигает 800% (рис. 7). ATI Radeon HD 2600 XT vs Intel(R) Core(TM)2 CPU 6320 @ 1.86GHz 200 400 600 800 1 000 neurons Рис. 7. Быстродействие CPU и GPU для нейросетей большой размерности Современное развитие архитектуры графических акселераторов позволяет использовать имеющиеся вычислительные мощности для реализации нейросете-вых алгоритмов и, в частности, алгоритма классификации. Применение подобного подхода на практике позволяет в ряде случаев получить существенное увеличение быстродействия работы нейросетевых алгоритмов. ]]></text>
</doc>
