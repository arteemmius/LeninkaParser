<doc>
  <source auto="true" type="str" verify="true"><![CDATA[https://cyberleninka.ru/article/n/uskorenie-vychisleniy-diskretnogo-logarifma-s-pomoschyu-tehnologii-cuda]]></source>
  <category auto="true" type="str" verify="true"><![CDATA[Автоматика]]></category>
  <author auto="true" type="list" verify="true">
    <item type="str"><![CDATA[Бабенко Людмила Климентьевна]]></item>
    <item type="str"><![CDATA[Сидоров Игорь Дмитриевич]]></item>
    <item type="str"><![CDATA[Кириллов Алексей Сергеевич]]></item>
  </author>
  <title auto="true" type="str" verify="true"><![CDATA[Ускорение вычислений дискретного логарифма с помощью технологии CUDA]]></title>
  <keywords auto="true" type="list" verify="true">
    <item type="str"><![CDATA[КРИПТОАНАЛИЗ]]></item>
    <item type="str"><![CDATA[ДИСКРЕТНОЕ ЛОГАРИФМИРОВАНИЕ]]></item>
    <item type="str"><![CDATA[ТЕХНОЛОГИЯ CUDA]]></item>
    <item type="str"><![CDATA[ПАРАЛЛЕЛЬНОЕ ПРОГРАММИРОВАНИЕ]]></item>
    <item type="str"><![CDATA[ВЫЧИСЛИТЕЛЬНО СЛОЖНЫЕ ЗАДАЧИ]]></item>
  </keywords>
  <annotation auto="true" type="str" verify="true"><![CDATA[Рассматриваются возможности дальнейшего ускорения реализации дискретного логарифмирования. Анализируется возможность применения технологии CUDA для ускорения вычислений на различных этапах. Рассматривается эффективная реализация необходимых арифметических операций. Приведены графики, построенные по результатам проведенных экспериментов.]]></annotation>
  <text auto="true" type="str" verify="true"><![CDATA[Рассматриваются возможности дальнейшего ускорения реализации дискретного логарифмирования. Анализируется возможность применения технологии CUDA для ускорения вычислений на различных этапах. Рассматривается эффективная реализация необходимых арифметических операций. Приведены графики, построенные по результатам проведенных экспериментов. Криптоанализ; дискретное логарифмирование; технология CUDA; параллельное программирование; вычислительно сложные задачи. L.K. Babenko, I.D. Sidorov, A.S. Kirillov SPEEDING UP DISCRETE LOG COMPUTATIONS USING CUDA TECHNOLOGY Different possibilities for further discrete log performance increase are considered. The capabilities of CUDA technology for speeding up different parts of computation process are analyzed. Here we represent effective implementation of needful arithmetic operations. Some graphic materials illustrate results of experiments. Cryptanalysis; discrete log problem; CUDA technology; parallel programming; computation intensive tasks. Введение. Постановка задачи. В настоящее время широко распространены алгоритмы шифрования и цифровой подписи (такие, как Эль-Гамаль, DSA, ГОСТ), стойкость которых основана на сложности решения задачи дискретного логарифмирования в мультипликативной группе числового поля и в группе точек эллиптической кривой над конечным полем. Для произвольной циклической группы G эта задача формулируется следующим образом: по известным a, b £ G найти такой логарифм х, что ab = X . Особенностью данной задачи является быстрый рост времени выполнения при увеличении размера задачи. Авторами был разработан ряд эффективных параллельных алгоритмов, предназначенных для ускорения решения задачи дискет-ного логарифмирования в различных группах с помощью распределённых многопроцессорных вычислений. Алгоритмы, предназначенные для мультипликативной группы числового поля, рассматриваются в работах [1,2], а алгоритмы для группы точек эллиптической кривой - в работе [3]. Тем не менее, многопроцессорные вычислительные системы на сегодняшний день по соотношению цены и производительности проигрывают специализированным ускорителям. Наиболее перспективными по соотношению таких параметров, как вычислительная мощность, цена, энергопотребление и удобство программирования, являются системы, построенные на базе видеокарт компании NVIDIA с поддержкой технологии CUDA. Технология CUDA(Compute Unified Device Architecture) предоставляет возможность программирования видеокарт с помощью расширения языка Си. Видеокарты, поддерживающие эту технологию, являются одновременно и SIMD вычислителями (так как один поток может выполнять вычисления над набором данных), и MIMD вычислителями (так как в видеокарте находятся несколько мультипроцессоров, способных выполнять несколько потоков одновременно). Применение CUDA даёт особенно хорошие результаты для задач, в которых присутствует обработка векторных данных. В сравнение с GPU, CPU ориентирован на максимально быстрое выполнение одного потока данных со случайным доступом к памяти. Все существующие на сегодняшний день способы распараллеливания являются надстройкой к общей идее и неспособны обеспечить кратный рост производительности. Таким образом, большинство процессоров, за исключением специализированных, не ориентированы на массивно-параллельные вычисления. GPU, в свою очередь, изначально разрабатывались под параллельные вычисления. Из структуры GPU можно увидеть, что есть большая память DRAM, доступ к которой возможен из любой вычислительной единицы. Вычислительные единицы называются потоковыми процессо-рами(SP), они объединяются в мультипроцессоры(MP). Один мультипроцессор представляет собой SIMD вычислитель. В мультипроцессоре также присутствует специализированный вид памяти(shared) быстрого доступа, расположенной на кристалле. Задача разбивается на участки (Warp), равные кол-ву SP в MP. Переключение потоков идет Warp’^a Количество мультипроцессоров определяется моделью используемого GPU. Таким образом, внутренняя архитектура вычислительных блоков GPU напоминает архитектуру специализированных процессоров, ориентированных на параллельные вычисления. Как говорилось выше, используется расширенная версия языка Си. По большей части, расширения представляют собой набор дополнительных директив, основные конструкции языка не меняются. Это достаточно сильно облегчает программирование, так как недостатком многих параллельных вычислительных систем является сложность модели их программирования и множество специфических конструкций языка. CUDA обладает очень хорошей масштабируемостью под задачу - достаточно указать размерность, а выполнение и переключение потоков берет на себя оборудование. В случае приобретения нового, более производительного GPU тот же код будет задействовать все возможные ресурсы без каких-либо вмешательств со стороны программиста. Прирост производительности в этом случае будет равняться приросту количества вычислительных единиц. Размерность задачи может быть указана множеством разных путей, исходя из программной модели вычислителя. Самым высоким уровнем является сетка(Grid), это двумерный массив. Его ширина и длина равна 65535. Далее, в каждом элементе этого массива находится блок(Block), максимальной размерностью 512*512*64, а в каждом блоке набор нитей(Threads) из 512 штук. Для определения того, какая именно часть задачи выполняется, введены специальные переменные, отражающие местонахождение потока в многомерной структуре. При реализации алгоритмов с большим количеством ветвлений, и при интенсивной работе с большими объёмами данных в оперативной памяти, эффективность CUDA снижается. В первом случае это происходит из-за того, что ветвление внутри Warp^ приводит к многократному просчету всех возможных вариантов для данного Warp^ (Один Warp это один MP с SIMD архитектурой), и в результате получается «последовательное» выполнение. Во втором случае снижение эффективности обусловлено медленной DRAM, в отличие от, например, Shared-памяти. Этапы дискретного логарифмирования. Рассмотрим, какие этапы дискретного логарифмирования можно эффективно реализовать с помощью CUDA. Дискретное логарифмирование на эллиптической кривой осуществляется с помощью методов встречи посередине и встречи на случайном дереве. Для обоих методов критическим ресурсом является не мощность процессора, а объём оперативной памяти [2]. Так как объём памяти видеокарты меньше, чем у компьютера общего назначения, а скорость обмена между видеокартой и оперативной памятью относительно невелика, то эффективность реализации подобных алгоритмов на CUDA на данный момент представляется невысокой. у—? * Вычисление логарифма в мультипликативной группе .г обычно выполняется с помощью субэкспоненциальных методов, например, решета числового поля. Эти методы содержат два вычислительно -сложных этапа - нахождения достаточного количества гладких чисел (просеивание) и построение с помощью этих соотношений уравнения, из которого и можно найти искомый логарифм. Второй этап вычислений обычно требует большого количества вычислений над элементами матрицы, которую необходимо разместить в оперативной памяти. Поэтому обычно эти вычисления эффективно проводятся на многоядерных вычислительных машинах, обладающих большим объёмом оперативной памяти. Вычисления отдельных элементов на этапе просеивания независимы, и вычислительная сложность этого этапа при большом размере модуля значительно превышает сложность этапа обработки матрицы. Поэтому имеет смысл рассмотреть возможность ускорения вычислений на этапе просеивания с применением параллельных вычислений по технологии CUDA Просеивание. Задача этапа просеивания состоит в нахождении достаточно большого количества чисел, гладких по базису из простых чисел для метода базы разложения, и гладких по базисам из простых чисел и простых идеалов для метода —решета” числового поля. Число называют гладким по заданному базису, если в его разложении на простые числа присутствуют только элементы базиса. После нахождения гладкого числа его нужно разложить на элементы базиса в виде (1) для метода базы разложения или в виде (2,3) для метода —решета” числового поля. n ^ р*‘ = ae”+1 be”+2, (1) i=1 n ^ рЄ‘ = (с + dm)(mod p), (2) i=1 n2 П qe = (с + da). (3) i=n+1 В формулах (1-3) a - основание логарифма, b - степень, pl - элементы базиса из простых чисел, qt - элементы базиса из простых идеалов в расширенном поле. На этапе просеивания отдельные кандидаты проверяются независимо, поэтому нет необходимости в хранении большого объёма данных в оперативной памяти. Рассмотрим, как можно выполнить проверку чисел на гладкость. Проверку числа на гладкость можно осуществить с помощью пробного деления, при этом в случае успеха сразу получается разложение числа - показатели при элементах базиса в формуле (1). Однако данный способ является не очень быстрым из-за необходимости осуществлять целочисленное деление длинных чисел — достаточно медленную операцию. Существует более быстрый способ проверки числа на гладкость. На этапе инициализации вычисляется проверочное число checker по формуле (4). chec ker = П p log Pi (4) Первый элемент базиса пропускается, так как это -1. Затем при проверке гладкости числа-кандидата cand производится вычисление НОД(Лескег,сапф. Если НОД(Лескег,саМ)=саМ, то данное число является гладким. Действительно, в разложение checker (4) входят все элементы базиса с максимально возможными для данного числа (саМ < р) степенями, поэтому, если в разложение саМ входят только элементы базиса, то НОД(Лескег, саМ)=саМ. Реализация арифметических операций на видеокарте. Для вычисления НОД используется бинарный алгоритм. Этот алгоритм замечателен тем, что использует только операции сравнения, вычитания и деления на два, которые очень легко реализовать на вычислительной машине даже для длинных чисел. Данный способ проверки на гладкость рекомендуется в [4]. Эксперименты, проведённые авторами, показали, что скорость просеивания с помощью НОД превосходит скорость просеивания пробным делением в 4 раза уже при длине модуля р, равной 75 битам [1], и преимущество возрастает при увеличении длины модуля, так как доля гладких чисел падает. Для первых экспериментов был выбран метод базы разложения, так как организация просеивания в нём проще, чем в методе решета числового поля. Фактически, для генерации чисел-кандидатов необходимо реализовать лишь умножение по модулю (и производную операцию возведения в степень) для получения правой части выражения (1). Рассмотрим особенности реализации для видеокарт операций умножения по модулю и нахождения НОД. Длинная арифметика в экспериментальных алгоритмах и программах реализована следующим образом. Число представляется в виде одномерного массива, первый элемент которого хранит количество разрядов, а остальные элементы -само число, записанное в обратном порядке, по правилу - младший разряд, младший адрес. Основание системы счисления выбиралось как максимально возможное для целых размером 24 бита, так как в текущей версии CUDA работа с такими целыми осуществляется в несколько раз (до 5 раз на видеокарте GTX260) медленнее, чем с 32-разрядными целыми. Особенностью реализации арифметических операций на CUDA было то, что для ускорения вычислений операнды, изначально находящиеся в памяти DRAM, перед началом вычислений размещались в shared-памяти. Shared-память находится непосредственно в процессоре видеокарты, и обращение к ней занимает намного меньше времени, чем обращение к DRAM [5]. Следовательно, когда большинство операций происходят в shared памяти, это значительно ускоряет процесс вычислений. Также, поскольку shared память выделяется на блок, и после вычислений данные теряются, то результат необходимо скопировать обратно в DRAM. 1=2 Ещё одна особенность заключается в том, что при проведении экспериментов в одном вычислительном блоке размещалось не множество нитей, а одна. При этом вычислительных блоков может быть много. Это обусловлено тем, что БИаге^ память выделяется на один блок. Если использовать множество нитей, то не исключены коллизии при обращении к памяти, приводящие к падению производительности. Чтобы их избежать, было выбрано размещение по правилу один блок -одна нить. Результаты экспериментов. Для проведения экспериментов авторами были разработаны программы, реализующие умножение, возведение в степень и нахождение НОД бинарным алгоритмом. Приведём результаты экспериментов для нахождения НОД, так как во-первых, эта операция является определяющей, а во-вторых, другие операции показали схожие результаты. На рис. 1 показана зависимость времени вычислений от количества проверяемых чисел. На рис. 2 - зависимость времени вычислений от разрядности проверяемых чисел. Врелля выпал не ния в зависимости от кол-ва чисел - канди датов 1400 ----- 1200 * си £ 1000 I Ї 800 § з 600 т 1 400 О- сй 200 0 5000 10000 15000 20000 25000 Кол-во чисел Рис. 1. Зависимость времени выполнения от числа кандидатов Время выполнения от разрядности чисел-кандидатов 800 700 | 600 = 500 | 400 т к 300 2 а. 200 100 о 0 20 40 60 80 100 120 Разрядность Рис. 2. Зависимость времени выполнения от разрядности чисел ------ери(гт) ------СРи(тз) Из графиков можно видеть, что скорость вычислений плавно уменьшается при росте размера числа и при увеличении количества проверяемых чисел. Также из графика видно, что производительность при использовании в данном эксперименте GPU GT250M возросла примерно в два раза по сравнению с процессором Intel Core 2 Duo 2 GHz. Заключение. Проведённые эксперименты показывают, что технология CUDA может эффективно использоваться для решения определённых задач асимметричной криптографии. Представляется, что проведя оптимизацию разработанных программ, можно добиться более существенного прироста производительности. Также перспективным направлением исследования является интеграция приложений для CUDA с уже разработанными распределёнными программами для получения полноценного инструмента дискретного логарифмирования. ]]></text>
</doc>
