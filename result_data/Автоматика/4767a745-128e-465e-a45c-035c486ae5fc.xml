<doc>
  <source auto="true" type="str" verify="true"><![CDATA[https://cyberleninka.ru/article/n/metod-dinamicheskoy-kontentnoy-filtratsii-setevogo-trafika-na-osnove-analiza-tekstov-na-estestvennom-yazyke]]></source>
  <category auto="true" type="str" verify="true"><![CDATA[Автоматика]]></category>
  <author auto="true" type="list" verify="true">
    <item type="str"><![CDATA[Тихомиров И. А.]]></item>
    <item type="str"><![CDATA[Соченков И. В.]]></item>
  </author>
  <title auto="true" type="str" verify="true"><![CDATA[Метод динамической контентной фильтрации сетевого трафика на основе анализа текстов на естественном языке]]></title>
  <keywords auto="true" type="list" verify="true">
    <item type="str"><![CDATA[КОНТЕНТНАЯ ФИЛЬТРАЦИЯ]]></item>
    <item type="str"><![CDATA[ЗАЩИТА СЕТЕЙ]]></item>
    <item type="str"><![CDATA[АВТОМАТИЧЕСКАЯ КЛАССИФИКАЦИЯ]]></item>
    <item type="str"><![CDATA[АНАЛИЗ ТЕКСТА]]></item>
    <item type="str"><![CDATA[ОБРАБОТКА ЕСТЕСТВЕННОГО ЯЗЫКА]]></item>
  </keywords>
  <annotation auto="true" type="str" verify="true"><![CDATA[В статье рассмотрен метод динамической контентной фильтрации сетевого трафика, основанный на алгоритмах автоматической классификации и анализе текстов на естественном языке. Предложен новый метод классификации гипертекстовых документов с использованием относительной значимости терминов.]]></annotation>
  <text auto="true" type="str" verify="true"><![CDATA[В статье рассмотрен метод динамической контентной фильтрации сетевого трафика, основанный на алгоритмах автоматической классификации и анализе текстов на естественном языке. Предложен новый метод классификации гипертекстовых документов с использованием относительной значимости терминов. Ключевые слова: контентная фильтрация, защита сетей, автоматическая классификация, анализ текста, обработка естественного языка. Введение Рост количества и объема ресурсов сети Интернет обусловливает необходимость поиска новых эффективных методов решения задачи ограничения доступа к ресурсам нежелательной тематики и содержания. Современные исследования показывают, что около 39 % рабочих компьютеров пользователей имеют неограниченный доступ в сеть Интернет [1]. При этом около 90 % пользователей признают использование служебного компьютера в личных целях, причем тратят на посещение ресурсов нежелательной тематики вплоть до 20 % своего рабочего времени [1]. Отсюда возникает потребность выявления нарушений корпоративного регламента, связанных с доступом в рабочее время вполне легитимных приложений пользователей (web-браузеров) к сайтам знакомств, сайтов «для взрослых», анекдотов и т. п. Современные системы ограничения доступа к сетевым ресурсам применяют комплекс различных методов, направленных на предотвращение доступа пользователя к нежелательной, нецелевой информации. Они имеют возможность контролировать по заданным ограничениям не только пакеты, но и их содержимое - контент. Одним из самых распространенных типов трафика в Интернет является HTTP-трафик, его доля составляет 46 % [2]. Задача систем контентной фильтрации заключается в блокировании доступа приложений пользователя к сетевым ресурсам, содержимое которых тематически определено как нежелательное. Одной из современных тенденций развития систем контентной фильтрации, в части контроля web-трафика, является переход от использования предопределенных баз данных категорий сайтов (web-ресурсов) к определению категории web-ресурса по содержимому его страниц (документов) [3]. Это стало особенно важным с развитием различных сетевых порталов, которые могут содержать наполнение различных категорий. В статье предложен метод решения задачи контентной фильтрации web-ресурсов, основанный на анализе гипертекстового содержания документов, с применением методов автоматической классификации и обработки текстов на естественном языке (ЕЯ). Подходы к решению задачи контентной фильтрации В настоящее время в системах контентной фильтрации применяются следующие методы фильтрации web-контента: по имени DNS или конкретному URL-адресу, по ключевым словам внутри web-контента и по типу файла. Фильтры представляют собой правила, ограничивающие или запрещающие доступ к ресурсам. Однако нельзя предугадать заранее все воз- 1818-7900. Вестник НГУ. Серия: Информационные технологии. 2008. Том 6, выпуск 2 © И. А. Тихомиров, И. В. Соченков, 2008 можные неприемлемые URL-адреса. Тем более, что некоторые web-узлы с сомнительным информационным наполнением работают не с URL, а исключительно с IP-адресами. Для разрешения или блокирования доступа к сетевым ресурсам в современных системах фильтрации содержимого применяются следующие подходы [3]: 1) использование предопределенных баз категорий ресурсов; 2) категоризация данных в момент обращения пользователя; 3) предоставление web-ресурсом своей категории. Каждый из этих методов имеет свои достоинства и недостатки. Предопределенные базы категорий ресурсов Использование заранее подготовленных баз адресов ресурсов и связанных с ними категорий - давно используемый и хорошо зарекомендовавший себя метод. В настоящее время такие базы предоставляют многие компании - Websence, Surfcontrol, ISS/Cobion, Astaro AG, NetStar и др. [3]. Категоризация данных и формирование баз категорий обычно производится в полуавтоматическом режиме. На первом этапе выполняется анализ содержимого документа и определяется его категория с помощью средств классификации. На втором этапе полученная информация проверяется экспертами. Преимуществом применения предопределенных баз категорий ресурсов является принятие решения о предоставлении или запрете доступа на этапе обращения к ресурсу (посылки запроса), что может существенно снизить нагрузку на каналы передачи данных. Главный недостаток использования данного подхода - задержки в обновлении баз категорий ресурсов. Кроме того, некоторые web-ресурсы достаточно часто меняют свое наполнение, из-за чего информация о категории, хранящаяся в базе адресов, становится неактуальной. Классификация ресурса на этапе обращения Другой подход к решению задачи состоит в фильтрации содержимого пакетов, возвращаемых в ответ на запрос пользователя. Для этого в системе контентной фильтрации назначается специальное правило, блокирующее документы, получаемые по протоколу HTTP, содержащие нежелательную строку или ключевое слово. Если нежелательная строка обнаруживается в HTTP-ответе web-сервера, страница будет блокирована [4]. Серьезным недостатком подхода является принятие решения о характере документа по вхождению какого-либо слова лишь в некоторый его фрагмент, что может значительно повысить число заблокированных страниц, не относящихся на самом деле к нежелательной тематике. Альтернативой является определение тематики документов с применением автоматического классификатора, который производит полнотекстовый анализ гипертекстового представления запрошенного документа и на его основе принимает решение об отнесении документа к одной из заранее предопределенных категорий. Для категоризации ресурсов при обращении к ним пользователя используются методы, основанные на статистическом подходе к анализу гипертекстового содержания. Категоризация данных «на лету» позволяет быстро реагировать на появление новых web-документов и сетевых ресурсов. Но такой подход имеет и недостатки - необходимо проводить анализ всех передаваемых данных, что вызывает некоторое снижение производительности системы в целом. Категоризация как самоидентификация ресурса Этот подход состоит в том, что ресурс сам сообщает о том, к какой категории он относится. Существует несколько путей реализации [3]: • PICS (Platform for Internet Content Selection) - спецификация, разработанная консорциумом W3Q цель - обеспечение надежности рейтинговой системы; для контроля может использоваться специальное разработанное программное обеспечение, доступное для загрузки со страницы проекта; • ICRA (Internet Content Rating Association) - инициатива, разрабатываемая независимой некоммерческой организацией с тем же названием; основная цель - защита детей от доступа к запрещенному содержимому. К достоинствам этого подхода необходимо отнести то, что для обработки данных нужно только специальное программное обеспечение и нет необходимости обновлять базы адресов и / или категорий, так как вся информация передается самим сайтом. Но недостатком является то, что сайт может указывать неправильную категорию или не указывать категорию вообще, а это приведет к неправильному предоставлению или запрещению доступа к данным. Как мы видим, каждый из рассмотренных подходов имеет достоинства и недостатки. Это означает, что наиболее эффективное решение задачи контентной фильтрации должно реализовывать комплексный подход, сочетающий все вышеизложенные методы. Таким образом, исследования в области автоматической классификации и интеллектуальной обработки текстов ЕЯ для создания системы категоризации текстовой и гипертекстовой информации являются весьма перспективными. Интеграция системы автоматической категоризации с системами контентной фильтрации позволит эффективно решить задачу динамического определения тематики web-документов и разграничения доступа к ним. Метод контентной фильтрации на основе автоматической классификации документов Предложенный нами метод динамической контентной фильтрации опирается на список доступа и систему автоматической классификации. Рассмотрим алгоритм, приведенный на рис. 1. С ) т Рис. 1. Алгоритм динамической контентной фильтрации От вызывающей системы принимается входящий запрос к НТТР-серверу, проверяется наличие запрошенного URL документа в списке доступа. Решение о блокировке ресурса принимается в соответствии с принадлежностью его URL к классу допустимых / нежелательных ресурсов. Если категория запрошенного документа не известна системе, необходимо: 1) получить гипертекстовое представление документа; 2) выделить из гипертекстового представления документа текст на ЕЯ; 3) подвергнуть выделенный текст лингвистическому анализу для преобразования текста в структурное представление; 4) классифицировать структурное представление в соответствии с выбранным методом классификации. После классификации адрес документа помещается в список доступа. Это позволяет не классифицировать документы / ресурсы при повторном обращении к ним пользователя, что позволяет снизить нагрузку на систему классификации и сетевую нагрузку. Предложенный подход обладает масштабируемостью и определенной гибкостью. Он может быть реализован как в системах контентной фильтрации, функционирующих на оборудовании пользователя (например, в виде подключаемого модуля для web-браузера), так и в системах, обеспечивающих фильтрацию трафика в локальной сети на промежуточном сетевом оборудовании. Важным требованием, предъявляемым к автоматическому классификатору, является соответствующий уровень качества классификации (высокие точность и полнота классификации), а также скорость классификации. Наибольшую вычислительную трудоемкость в процессе классификации электронного гипертекстового документа представляют лингвистический анализ и процедура классификации. В зависимости от выбранной модели представления документа и метода классификации лингвистический анализ может быть морфологическим, синтаксическим и семантическим. Возможность регулировать уровни полноты и точности классификации представляет собой важный механизм настройки классификатора. Оптимальное решение зависит от практических задач применения фильтра. В одних случаях потребность в доступе к информации является наиболее важной, поэтому недопустимы «ложные» срабатывания системы фильтрации: точность важнее полноты. В других случаях, напротив, важнее не пропустить нежелательную информацию. В такой ситуации необходимо обеспечить максимальную полноту фильтрации, а точность может находиться в пределах заранее заданных допустимых значений [5]. Поэтому необходима самостоятельная «пользовательская» настройка алгоритма классификации. Далее описан метод классификации, опирающийся на понятие относительной значимости терминов ЕЯ (отдельных слов или словосочетаний). Для применения этого метода требуется проведение морфологического и частичного синтаксического анализа текста. Метод автоматической классификации документов на основе характеристики относительной значимости терминов В основе рассматриваемого метода автоматической классификации гипертекстовых документов лежат законы Ципфа - Мандельброта [6]. Пусть T = [t, | I = 1..M} - множество текстов на ЕЯ (коллекция текстовых документов). Каждый текст tj, i = 1..M представляет собой множество терминов (слов или словосочетаний ЕЯ): t, = [wj I j = 1..Kj}. Рассмотрим статистические величины, выражающие информационную значимость терминов в T. Частота встречаемости термина Wj в тексте t, countW, t,) TF (Wj, tj) = log2 ---, £ count(w^, t,) k=1 где count(Wj, t) - количество вхождений термина Wj в текст t,. Частота встречаемости есть вероятность выбрать термин Wj в тексте t, при случайном выборе из множества всех вхождений терминов, составляющих этот текст. Инверсная частота встречаемости (IDF) термина Wj в коллекции текстов T: м 1БР(м,, Т) = 1оя2------— { £ Т | ^ £ /}| ГОР определяет количество информации, получаемое при снятии неопределенности наступления события: «встретить термин в некотором документе из множества Т». Заметим, |Т| что ,-----1------г > 1, следовательно, ГОР(У,, Т) > 0 . { £ Т|М] £ 0| ] Для терминов, которые встречаются в большей части текстов коллекции, величина 1БР(, Т) близка к 0; для редких терминов она стремится к 1од2 |т| слева: 0 < ГОР^., Т) < 1оя2 |Т| Рассмотрим подмножество текстов Т'с Т , объединяющее тексты по некоторой тематике. Пусть t 6 Т и 1 - слово в документе. Величина ГОР^, Т), вычисленная относительно этого множества Т, есть тематическая ГОР термина М]. Разность М0(м’1 , Т, Т ') = ГОР(м1 , Т) - ГОР(м1 , Т) (1) определяет изменение информативности термина при отнесении t' к подмножеству Т. Величина 10(М], Т, Т) может быть как положительной, так и отрицательной. Поскольку отнесение t' к подмножеству Т означает снятие некоторой информационной неопределенности относительно тематики документа (а следовательно, и о его содержании), то Д/(М], Т, Т') = и (Д/0(^1, Т, Т')) . (Д/0 (М], Т, Т')) (2) определяет величину изменения количества информации при отнесении t' к подмножеству Т. Здесь и (г) = Ц <0 - индикаторная функция Хевисайда. Заметим, что в силу формул (1), (2), поскольку ШР(, Т) > 0, имеет место соотношение 0 <Д/(^, Т, Т') < ГОР^., Т). (3) Введем в рассмотрение понятие значимости термина. Согласно [6; 7] под значимостью термина в тексте t, входящего в множество документов Т понимается величина: ТРГОР^., t, Т) = ТР(м] , t) • ГОР(^ , Т). (4) По аналогии с (4) рассмотрим величину ТРДВР^, t, Т, Т’) = ТР^., t) • Д/(^, Т, Т'), которая характеризует значимость термина в тексте ¿, входящего в множество документов Т, с учетом того, что текст t также относится к подмножеству Т'с Т . Величину ТРЯБР будем называть характеристикой значимости термина относительно множества документов Т (или просто характеристикой относительной значимости (ХОЗ) термина). В силу формулы (3) справедливо соотношение ТРДВР^., t, Т, Т') < ТРГОР^., t, Т). (5) Характеристика относительной значимости термина аналогично ТРГОР-значимости позволяет выделять значимые, т. е. обладающие наибольшей информативностью, термины -ключевые слова классов текстов. Термин, для которого выполнено соотношение Д/(М], Т, Т') > 0 будем называть значимым термином класса документов Т' с Т . Опишем далее применение введенных величин для решения задачи автоматической классификации. Пусть С = {с- | г = 1..Л^} - множество априорно заданных классов текстовых документов. Каждому классу с, г = 1. N множества С соответствует структурное описание Si, г = 1.^ из множества структурных описаний классов S, построенное на основе текстовых документов обучающей выборки. Каждое описание si = {^;- |] = 1..Кг} есть множество значи- N мых терминов соответствующего класса с; s' - структурное метаописание для ^ есть г=1 множество терминов описаний всех классов, для которых на этапе обучения классификатора вычислены величины ШР(Wj, 5'). Будем считать, что для терминов каждого метаописания г = 1..Nна этапе обучения также рассчитаны величины А/(М], 5, 5' ). Характеристика значимости текста документа t относительно класса с есть К1С(/, , 5') = ^ TFtIDF(w, t, 5г., 5'). nt ХОЗ - это суммарная значимость терминов текста документа в контексте некоторого класса. Учитывая, что Ц- п ¿| < |/| и принимая во внимание соотношение (5) , получаем нормированный вариант ХОЗ: ^ TFtIDF(w, t, , 5 ’) (t, А) , 5 ') = -------------- , ^ TFIDF(w, t, 5') wеt для которого справедливо соотношение 0 < RICN (t,, 5') < 1. (6) Соотношение (6) позволяет использовать ХОЗ в решающем правиле классификации: текст документа t относится к классу сг тогда и только тогда, когда выполнено условие RICN (Г, 5-, 5 ’) > Ес , где Ес - пороговая константа, подбираемая на этапе настройки классификатора. Заключение В статье рассмотрен подход к задаче динамической контентной фильтрации НТТР-трафика, основанный на применении автоматической классификации запрашиваемых документов. Предложен метод классификации гипертекстовых документов, учитывающий относительную значимость терминов. Введено понятие характеристики относительной значимости текста документа при отнесении к некоторому классу. Показано, что ХОЗ может быть применена в решающем правиле классификации для принятия решения об отнесении текста документа к одному или нескольким классам документов нежелательной тематики. Пороговая константа Ес является настроечным параметром и предоставляет механизм настройки классификатора на необходимый уровень соотношения точности и полноты. Предложенный метод классификации требует выделения текста на ЕЯ из гипертекстового представления документа и проведения морфологического и синтаксического анализа текста. Процедура классификации имеет линейную вычислительную сложность: трудоемкость линейно зависит от количества терминов, входящих в состав текста и от количества классов нежелательной тематики. Это позволяет говорить о высокой скорости классификации, что в свою очередь дает возможность рассматривать предложенный метод как универсальный: классификация и динамическая контентная фильтрация могут производиться как на рабочих станциях пользователей, так и на выделенных серверах фильтрации, обеспечивающих безопасность локальных сетей. Направлениями дальнейших исследований являются: 1) модификация модели представления документа и расчет веса терминов с учетом окружающей теговой разметки в гипертекстовом представлении документа с целью представления ХОЗ в виде взвешенной суммы произведения тегового веса термина и его относительной значимости; 2) исследования в области ссылочного ранжирования гипертекстовых документов для разработки механизмов автоматической классификации, учитывающих ссылки на документы известной тематики; 3) оценка эксплуатационных характеристик предложенного метода в реальных условиях функционирования крупных СПД. ]]></text>
</doc>
