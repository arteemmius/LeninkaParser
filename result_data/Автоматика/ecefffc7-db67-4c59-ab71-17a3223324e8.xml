<doc>
  <source auto="true" type="str" verify="true"><![CDATA[https://cyberleninka.ru/article/n/obnaruzhenie-anomalnogo-povedeniya-polzovatelya-v-operatsionnoy-sisteme-windows-na-osnove-analiza-raboty-s-prilozheniyami]]></source>
  <category auto="true" type="str" verify="true"><![CDATA[Автоматика]]></category>
  <author auto="true" type="list" verify="true">
    <item type="str"><![CDATA[Сидоров М. В. Аникеев И. Д.]]></item>
  </author>
  <title auto="true" type="str" verify="true"><![CDATA[Обнаружение аномального поведения пользователя в операционной системе Windows на основе анализа работы с приложениями]]></title>
  <keywords auto="true" type="list" verify="true"/>
  <annotation auto="true" type="str" verify="true"><![CDATA[]]></annotation>
  <text auto="true" type="str" verify="true"><![CDATA[Традиционно системы обнаружения вторжений (атак) подразделяются на системы обнаружения злоупотреблений и системы обнаружения аномалий [1]. К злоупотреблениям относятся известные атаки, которые используют известные уязвимости системы. Аномалии означают любую необычную деятельность, которая потенциально может указывать на атаку. Если наблюдаемая деятельность пользователя не соответствует ожидаемому режиму работы, то говорят, что имеет место аномалия. Основной проблемой при проектировании систем обнаружения аномалий является определение, какое поведение пользователя можно считать обычным, а какое содержит признаки аномалий. Необычное, но санкционированное использование иногда может рассматриваться как аномальное, что ведёт к росту числа ложных срабатываний. С другой стороны, если проектировать систему, основываясь на известных примерах аномального поведения, система будет неспособна обнаруживать нестандартные атаки. Одним из распространённых подходов к решению этой проблемы является создание профилей стандартного поведения индивидуальных пользователей в конкретной системе вместо создания единого профиля санкционированного поведения многих пользователей. При этом поведение характерное для одного из пользователей может считаться необычным для другого и наоборот. Поскольку такие профили трудно формализовать, предлагается их создавать на основе примеров нормальной работы того или иного пользователя. В качестве средства представления профилей были выбраны нейронные сети, благодаря их способности обучаться на примерах. В ряде работ по обнаружению аномалий [2, 3, 4] в качестве информативных признаков режима работы пользователя были выбраны характеристики использования различных команд оболочки операционной системы. Поскольку для работы в операционных системах семейства Windows использование командной оболочки крайне нетипично, такой подход становится неприемлемым. В Windows аналогом работы с командной оболочкой можно считать запуск и завершение приложений, а также переход от одного активного приложения к другому. В данной статье рассматривается система обнару- жения аномального поведения, основанная на специфике работы индивидуальных пользователей с приложениями операционной системы Windows 2000. Вектор, характеризующий активность пользователя, формируется на основе работы перехватчика активности приложений следующим образом: Выбирается интервал времени, за который будет подсчитываться вектор. За время сеанса работы пользователя с операционной системой составляется протокол запуска, завершения и активизации приложений, который разбивается на участки выбранной длины, причём учитывается только время активной работы -когда запущено ненулевое число процессов и интервал между двумя событиями не превышает некоторого критического времени - порога бездействия. На этих участках подсчитывается статистика работы с процессами. Для каждого процесса вычисляется, сколько времени он был запущен и сколько времени n он был активен. Время работы за интервал подсчитывается по формуле ^ d - at), 1=1 где n - число запусков/завершений процесса, di - время i-того завершения, ai - n время i-того запуска. Время активности вычисляется по формуле ^ (z. - х,), где xi i=1 - время, когда произошла активация искомого процесса, zi - время, когда произошла активация другого процесса. Статистика нормируется, то есть значения времени делятся на общую длительность интервала. В результате значения оказываются в интервале [0;1]. Если всего в протоколе фигурируют n программ, в итоге мы получаем вектор действительных чисел размерности 2*n. Для формирования обучающей выборки были выбраны 5 пользователей (Ar-tem, Igor, Juic, Max, Stas). Перехватчик активности процессов контролировал их активность в течение 3-х дней. В итоге была подсчитана статистика со следующими параметрами: Интервал активности пользователя - 3600 секунд (1 час) Порог бездействия пользователя - 3600 секунд Число процессов - 85, формировалось по итогам всех протоколов работы. Число векторов, полученных в результате, представлено в табл. 1. __________________________________________________________________Таблица 1 Пользователь Число векторов Artem 10 Igor 10 Juic 19 Max 16 Stas 17 Итого 72 Для каждого пользователя была сформирована обучающая выборка и каждому пользователю была поставлена в соответствие нейронная сеть. Каждая нейронная сеть была обучена выдавать на выходе вектор <1;0> при предъявлении векторов с признаками характерной работы соответствующего пользователя, и вектор <0;1> при предъявлении «чужих» векторов. Максимально допустимое значение ошибки - 0.001. Обучение проводилось методом гибкого обратного распространения (resilient backpropagation) [5], нейросети затратили на обучение от 8 до 18 итераций (эпох). Тестовая выборка была сформирована из протоколов работы тех же пользователей в течение следующего дня. Число векторов в тестовой выборке приведено в табл. 2. Классификация идёт следующим образом: (свой > 0.7) И (чужой < 0.3) = свой (свой < 0.3) И (чужой > 0.7) = чужой (НЕ свой) И (НЕ чужой) = ((свой < 0.7) ИЛИ (чужой > 0.3)) И ((свой > 0.3) ИЛИ (чужой < 0.7)) = не классифицирован _________________________________________________________________Таблица 2 Пользователь Число векторов Artem 2 Igor 8 Juic 12 Max 11 Stas 5 Итого 38 Результаты тестирования приведены в табл. 3. Таблица 3 Тест Предъявлено Правильно классиф. Неверно классиф. Не классиф. Всего 190 177 5 8 Свой пользователь 38 34 2 2 Чужой пользователь 152 143 3 6 По данным табл. 3 можно оценить вероятность ошибки первого рода (ложная тревога) диапазоном 6-10%, вероятность ошибки второго рода диапазоном 2-6%. Таким образом, предложенный метод позволяет достаточно эффективно сигнализировать о нестандартном поведении пользователей при работе с компьютерами на базе Windows. Такое нестандартное поведение нельзя однозначно ассоциировать с вторжением. Однако при проявлении других признаков атаки, данные такой системы могут ускорить поиск её источника или получить о ней дополнительную информацию. ]]></text>
</doc>
