<doc>
  <source auto="true" type="str" verify="true"><![CDATA[https://cyberleninka.ru/article/n/resursonezavisimoe-programmirovanie-mnogoprotsessornyh-sistem]]></source>
  <category auto="true" type="str" verify="true"><![CDATA[Автоматика]]></category>
  <author auto="true" type="list" verify="true">
    <item type="str"><![CDATA[Левин И.И.]]></item>
    <item type="str"><![CDATA[Дордопуло А.И.]]></item>
    <item type="str"><![CDATA[Гудков В.А.]]></item>
  </author>
  <title auto="true" type="str" verify="true"><![CDATA[Ресурсонезависимое программирование многопроцессорных систем]]></title>
  <keywords auto="true" type="list" verify="true"/>
  <annotation auto="true" type="str" verify="true"><![CDATA[]]></annotation>
  <text auto="true" type="str" verify="true"><![CDATA[В настоящее время параллельные программы, разработанные для многопроцессорной вычислительной системы (МВС), не могут быть выполнены на системе с другой конфигурацией и требуют полной переработки для других архитектур . приложений при реконфигурации или изменении архитектуры системы необходима разработка методов и средств ресурсонезависимого программирования. , различных многопроцессорных системах язык программирования должен обладать гибкостью описания задачи для большинства существующих архитектур. Поэтому язык должен эффективно реализовывать вычислительный алгоритм на различных , -, -личные виды параллелизма в достаточно сжатом виде и содержать мощные конструкции как в традиционных языках высокого уровня. Предлагается в качестве базового языка ресурсонезависимого программирования использовать язык параллельного программирования СОЬЛМО[1]. Формально язык СОЬЛМО предназначен для описания параллельной структурнопроцедурной организации вычислений (СПОВ)[2]. Структурно-процедурные вычисления представляют собой единую управляющую программу вызова структур-но-реадизуемых фрагментов задачи. Каждый фрагмент реализуется аппаратно на основе метода потока операндов. СПОВ наиболее эффективно выполняется на , -ментов и элементов памяти, объединенных между собой пространственной комму. Фундаментальным типом вычислительной структуры в языке СОЬЛМО является конструкция "кадр". Кадром является программно-неделимая компонента, представляющая собой совокупность арифметико-логических команд, выполняемых на различных элементарных процессорах, обладающих распределенной памятью и соединенных между собой в соответствии с информационной структурой алгоритма таким образом, что вычисления производятся с максимально возможными параллелизмом и асинхронностью. В языке отсутствуют явные формы описания параллелизма. Распараллеливание достигается с помощью объявления типов переменных и индексации элемен-. , -ния параллелизма в программе является правило единственной подстановки, кото- рое широко используется в языках потока данных и заключается в следующем: переменная может получить значение в программе только один раз. Данное правило приводит к противоречию с традиционными принципами программирования. В связи с этим делается следующее ограничение: правило единственной подстановки действует в пределах кадра. Для обращения к данным используются два основных метода доступа: параллельный доступ (задаваемый типом Vector) и последовательный доступ (задаваемый типом Stream). На рис. 1 представлены программы, являющиеся граничными примерами извлечения параллелизма, и графы вычислительных структур, в которые они будут оттранслированы. Применение неявного описания параллелизма позволяет достаточно просто управлять степенью распараллеливания программы на уровне описания структур данных. VAR A,B,C :VECTOR [10]; CADR SummaVec-tor; begin C=A+B; end; ENDCADR; B[l| A[10| B[10| C[l| C[10| A[10] B[10] VAR A,B,C :STREAM [10]; CADR SummaStream; begin C=A+B; end; ENDCADR; A[2] A[1] B[2] B[1] Ьеи C[1] C[2] Pnc.1. Параллельное и последовательное сложение массивов б а Используемые типы доступа к переменным определяют основные типы данных в языке COLAMO: Vector (вектор), Number (число), Stream (поток), Array ( ), . -, -тельно. Вектором является массив, элементы которого могут быть обработаны параллельно. Многомерные массивы состоят из множества измерений, каждое из которых может иметь последовательный или параллельный тип доступа и, соот-, Stream Vector. Проводимые исследования показали возможность использования предлагаемого языка для ресурсонезависимого программирования, т.е. для разработки па, -процедурной организацией вычислений, так и на МВС других архитектур. Это связано с тем, что структурно-процедурные вычисления являются обобщенной , COLAMO для ресурсонезависимого программирования других конвейерных архитектур с . Кадровая форма может также использоваться как унифицированное представление параллельного алгоритма задачи, которое в дальнейшем может быть представлено в структуре, учитывающей особенности архитектуры и конфигурации МВС. Так, кадровая форма может быть переведена в форму для мультипроце- , , , -тектур. Функцию перевода кадровой формы в формы, учитывающие особенности архитектуры и конфигурации МВС, выполняют трансляторы. В соответствии с идеологией кластерных вычислений для организации управления вычислительным процессом в кластере выделяется вычислительный узел, осуществляющий рассылку и сбор данных. Для осуществления вычислений на узлах кластера возможны следующие методы трансляции операторов описания и обработки данных: 1. . 2. Последовательная обработка данных в кластере. Для метода параллельной обработки данных, исходя из общего количества вычислительных узлов кластера, для обеспечения максимальной, равномерной загрузки кластера рассчитывается количество данных типа Vector, которое будет обрабатываться одним вычислительным узлом. Если число машин в кластере пре- Vector, необходимое для вычислений число узлов кластера. После этого можно генериро-( , C++ MPI) - . -, ( ) . Для метода последовательной обработки данных, исходя из общего количества вычислительных узлов кластера, для обеспечения максимальной, равномерной загрузки кластера рассчитывается число арифметических выражений, которые будут обрабатываться одним вычислительным узлом. Если число узлов в кластере превышает количество требуемых к обработке арифметических выражений, то для обработки будет задействовано только необходимое для вычислений число узлов. После этого для каждого используемого вычислительного узла можно генериро- C++, - ные и необходимые для вычисления арифметические выражения. COLAMO ++ MPI - нована на использовании виртуального дерева программы, получаемого в результате лексического и синтаксического анализа. Виртуальное дерево представляет , . - COLAMO ++ - MPI , - , : 1. . 2. « » . 3. Трансляция описаний операторов (цикла, условия, перехода и т.д.). 4. Трансляция описаний арифметических выражений. Рассмотренные выше методы и алгоритм трансляции позволяют получить ис- ++, COLAMO, - тода трансляции операторов описания и обработки данных. Для иллюстрации алгоритма рассмотрим пример вычислений, который демонстрирует обработку данных с параллельным типом доступа. Программа на языке COLAMO: program MultiCadr; module 1; var K,I : Number; Define K = 5; var A, B, C, D : Vector [5] Mem; Begin_Program Cadr Evaluate_C_D begin For I=1 to k do begin C[I] = A[I]*A[I] + B[I]*B [I]; D[I] = A[I]*A[I]*A[I] - B[I]*B [I]*B[I]; end; end; EndCadr; OutPut(C,D); End_Program. ++ #include "mpi.h" #include <stdlib.h> #include <stdlib.h> int K = 5; int I = 0; int A [ 5 ]; int B [ 5 ]; int C [ 5 ]; int D [ 5 ] ; int main (int argc, char *argv[]) { int Me, Size, OffSet, Processor; int Master=0; int Slave=1; MPI_Status status; MPI_Init(&argc,&argv); MPI_Comm_rank (MPI_COMM_WORLD, &Me); MPI_Comm_size (MPI_COMM_WORLD, &Size); if (Me == 0) { for (Processor = 1; Processor <= Size; Processor++ ) { MPI_Send (&A , 5,MPI_INT, Processor , Master , MPI_COMM_WORLD ); MPI_Send (&B , 5,MPI_INT, Processor , Master , MPI_COMM_WORLD ); MPI_Send (&C , 5,MPI_INT, Processor , Master , MPI_COMM_WORLD ); MPI_Send (&D , 5,MPI_INT, Processor , Master , MPI_COMM_WORLD ); }; for (Processor = 1; Processor <= Size; Processor++ ) { MPI_Recv (&A , 5 ,MPI_INT, Processor , Slave , MPI_COMM_WORLD, &status ); MPI_Recv (&B , 5 ,MPI_INT, Processor , Slave , MPI_COMM_WORLD, &status ); MPI_Recv (&C , 5 ,MPI_INT, Processor , Slave , MPI_COMM_WORLD, &status ); MPI_Recv (&D , 5 ,MPI_INT, Processor , Slave , MPI_COMM_WORLD, &status ); }; } else { OffSet = ((K / Size ) * (Me - 1)); for ( I=OffSet + 1; I<= ((( K)/ Size) * Me); I++ ) { C [I]=A[I]*A[I]+B[I]*B[I]; D[I]=A[I]*A[I]*A[I]-B [I]*B[I]*B [I]; }; MPI_Barrier(MPI_COMM_WORLD); for (Processor = 1; Processor <= Size; Processor++ ) { MPI_Send (&C , 5 ,MPI_INT, 0 , Slave , MPI_COMM_WORLD ); MPI_Send (&D , 5 ,MPI_INT, 0 , Slave , MPI_COMM_WORLD ); }; }; MPI_Finalize(); }; Данный пример демонстрирует обработку переменных сразу на всех процессорах кластера. Переменная Processor определяет номер процессора, который об. Count , который необходимо обработать; Size - количество процессоров в кластере; Offset - задает смещение в массиве, т.е. задает индекс элемента, с которого должна начаться обработка данных процессором. Проведенные исследования показали эффективность использования COLAMO . COLAMO - висимого программирования для переноса параллельных программ между МВС , , кросс-платформенных языков высокого уровня. Применение технологии ресурсонезависимого программирования позволит сократить объем кода, сократить затраты времени на разработку программ и снизить требования к квалификации про. В качестве развития предложенного подхода в настоящее время ведется раз- COLAMO трансляция в язык VHDL, являющегося базовым средством для программирования реконфигурируемых систем на основе ПЛИС. ]]></text>
</doc>
