<doc>
  <source auto="true" type="str" verify="true"><![CDATA[https://cyberleninka.ru/article/n/primenimost-kompaktno-podderzhivaemyh-neyronnyh-setey-dlya-resheniya-differentsialnyh-uravneniy-v-chastnyh-proizvodnyh-metodom]]></source>
  <category auto="true" type="str" verify="true"><![CDATA[Автоматика]]></category>
  <author auto="true" type="list" verify="true">
    <item type="str"><![CDATA[Земскова Ю. Н.]]></item>
  </author>
  <title auto="true" type="str" verify="true"><![CDATA[Применимость компактно поддерживаемых нейронных сетей для решения дифференциальных уравнений в частных производных методом конечных элементов]]></title>
  <keywords auto="true" type="list" verify="true">
    <item type="str"><![CDATA[компактно поддерживаемая радиальнобазисная нейронная сеть]]></item>
  </keywords>
  <annotation auto="true" type="str" verify="true"><![CDATA[В данной работе рассматриваются численные методы решения дифференциальных уравнений в частных производных (ДУЧП). Предложено использование радиальнобазисных нейронных сетей для реализации метода конечных элементов при решении ДУЧП.]]></annotation>
  <text auto="true" type="str" verify="true"><![CDATA[© Ю. н. ЗЕМСКОВА Пензенский государственный педагогический университет им. В. Г. Белинского кафедра вычислительных систем и моделирования e-mail: zjn21@mail.ru Земскова Ю. Н. - Применимость компактно поддерживаемых нейронных сетей для решения дифференциальных уравнений в частных производных методом конечных элементов // Известия ПГПУ им. В. Г. Белинского. 2009. № 13 (17). С. 144-148. - В данной работе рассматриваются численные методы решения дифференциальных уравнений в частных производных (ДУЧП). Предложено использование радиально-базисных нейронных сетей для реализации метода конечных элементов при решении ДУЧП. Ключевые слова: компактно поддерживаемая радиально-базисная нейронная сеть. Zemskova J. N. - Applicability of compactly supported neural networks for solution of partial differential equations with finite element method // Izv. Penz. gos. pedagog. univ. im.i V. G. Belinskogo. 2009. № 13 (17). P. 144-148. - The numerical methods of solution of differential equations in partial derivatives is considered in this work. The employment of radial-basis neural networks is offered for realization of finite element method at solution of partial differential equations. Keywords: compact supported radial-basis neural network. Основы метода конечных элементов Пусть в области Q = Q + T необходимо решить некоторую дифференциальную задачу [1]. Данную область разбивают на подобласти - элементы, которые не пересекаются. В каждом конечном элементе выбирается система нумерованных узлов, в которых значения искомой функции являются неизвестными величинами. Каждому нумерованному узлу приписывается базисная функция, равная единице в нем, а в остальных нумерованных узлах равная нулю. Число базисных функций в расчетной области равно числу нумерованных узлов. Решение искомой дифференциальной задачи строится в виде линейной комбинации базисных функций по всем нумерованным узлам расчетной области с коэффициентами линейной комбинации, равными значениям искомой функции в нумерованных узлах. Это решение подставляется в дифференциальную задачу. Результатом подстановки будет функциональная невязка. С помощью известных методов взвешенных невязок (коллокаций, Галеркина, наименьших квадратов) функциональная невязка минимизируется по всей расчетной области путем приравнивания нулю скалярного произведения функциональной невязки и весовых функций. В результате получается система линейных алгебраических уравнений (СЛАУ) относительно значений искомой функции в нумерованных узлах. Бессеточные методы В стандартных численных методах априори требуется информация о межузловой связности, то есть они, по определению, сеточные. Метод конечных элементов и метод конечных объемов - наиболее универсальные в этом семействе всесторонне изученных численных методов. В последнее время появились новые методы, которые аппроксимируют уравнения в частных производных, основываясь только на наборе узлов [2], без знания дополнительной информации о структуре сетки. Метод конечных элементов с применением нейронной сети В работах [3,4] применяются радиально-базисные функции в качестве базисных функций при составлении уравнений минимизации невязки с последующим решением данной СЛАУ. В данной работе предлагается использование радиально-базисных компактно поддерживаемых функций в качестве базисных функций. Использование компактной поддержки позволяет уменьшить трудоемкость вычислений. Нахождение невязки будет производиться лишь в области поддержки данной функции. В связи с этим снимается проблема плохой обусловленности матрицы. Однако остаётся проблема подбора размера компактной поддержки по отношению к ширине радиально-базисных функций. Данная проблема решается экспериментальным путём. Ниже приводится формулировка краевой задачи. В области Q = Q + Г решается краевая задача Lu + p = 0 в Q; (1) Bu + q = 0 на Г, (2) где L и B - линейные дифференциальные операторы, а p и q - известные функции независимых переменных. Область Q разбивается на M конечных элементов. Точки разбиения области являются узлами. Узлы конечных элементов будут центрами радиально-базисных функций Nm, с помощью которых производится аппроксимация функции решения M u = И = X um • Nm , (3) m=1 где um,m = 1,M - веса. Подстановка (3) в (1) и в (2), и последующее возведение (1) и (2) в квадрат даст невязку L|Xu ■ N | + p| = residualxeQ; 1: 2 (4) BI X um • Nm 1 + q I = residualxеГ. V m=M 1 ) ) Главная задача - найти веса или коэффициенты линейной комбинации (3), при которых residual ^ 0 в (4). Как отмечалось выше, в узлах конечных элементов, располагаются центры аппроксимирующих функций. В терминах нейросетевой методологии данные центры будут являться нейронами. В данном исследовании используется компактно поддерживаемая радиально-базисная функция [3] N (х )= е-М )У(c2)_ e-rV(c2) r2 1 _ e (x _ x )^r; ^/'(-е2) ’ V * (5) 0 , (х - xi )> г, где г - область компактной поддержки, с - ширина, х{ - центр радиально-базисной функции. Компактно поддерживаемая радиально-базисная нейронная сеть - это сеть, функциями нейронов которой являются компактно поддерживаемые радиально-базисные функции. Точка х, которая удовлетворяет условию (х - х{ )< г, будет входом нейронной сети. Коэффициенты ит,т = 1,М - веса нейронной сети, которые надо найти. Таким образом, получаются компактно-поддерживаемые радиально-базисные нейронные сети. Для того чтобы найти веса можно использовать градиентные алгоритмы обучения нейронной сети [5, 6]. Точки обучающего множества берутся внутри получившихся областей, а также добавляются сами узлы разбиения. Эксперименты Метод конечных элементов с применением нейронной сети использовался при решении одномерных задач. Цель экспериментов - исследовать применимость компактно поддерживаемых нейронных сетей для решения дифференциальных уравнений в частных производных методом конечных элементов. Решалось уравнение y"(x )= -4sin (2x), при граничных условиях y (0) = 0, y (2п)= 0. Аналитическое решение данной задачи имеет вид y(x)= sin(2x). Область компактной поддержки принималась равной r = 4с. Область определения задачи разбивалась на различное количество элементов. Рассчитывалась относительная среднеквадратическая ошибка решения или норма ошибки решения Ne, определяемая следующим образом: N Xq [“ (*W)" Ue (*W)_ и ue , где uyx ' ) и идх^' f - соответственно, вычисленное и точное решение в точке i, /ЕI». (>в)‘ q - количество точек, в которых происходило обучение. Исследовалось влияние числа точек разбиения, или количества элементов на меру средней погрешности решения Ne. Узлы элемента ассоциируются с нейронами. В данной задаче узлы располагаются на одинаковом расстоянии. Число нейронов будет совпадать с числом узлов. По [6] число узлов m находится в соотношении m <х N число узлов, тогда m-1 - число элементов. Число точек обучающего множества m3. В число точек обучающего множества входят также число нейронов-узлов. Данные точки-узлы стационарны в процессе обучения. Остальные обучающие точки, число которых m3-m, находящиеся между ними, генерируются случайным образом в процессе обучения. данные точки должны равномерно распределиться по области, то есть внутри каждого элемента будет находиться одинаковое количество m(m+1) обучающих точек. Чтобы исключить явление переобучения сети, на каждом наборе обучающих точек проводилось 3 - 5 циклов обучения. Процесс обучения осуществляется до тех пор, пока относительная норма вектора весов U—I, где k - IMI номер итерации, не упадет ниже заданного малого значения. Если данное значение не достигнуто, то процесс обучения остановится после выполнения заданного большого количества циклов обучения. На каждом цикле обу- Xq и(х^1')-ue(,W)1 i U)\ чения подсчитывается среднеквадратичная ошибка —-------------1----'-LL-, где ue ixu ) - заданное значение в q i-той точке, u (x(i)) - полученное значение в i-той точке, q - количество точек. Когда получено решение, то аналогично находится среднеквадратичная ошибка между аналитическим решением и полученным. На основании этого делается вывод об обобщающей способности сети. Область определения [0,2п] разбивалась на десять, двадцать, тридцать элементов. Результаты представлены в таблице 1 и на рисунках 1-3 соответственно. Задача решалась на компьютере с процессором Intel Core2 Duo Т5750 2.00ГГерц с оперативной памятью - 2.00 ГБ. Таблица 1 Сравнительный анализ для экспериментов с различным числом элементов Кол-во элементов Время выполнения Норма ошибки решения Ne Среднеквадратичная ошибка на последней итерации среднеквадратичная ошибка полученного решения и аналитического 10 223 с 0.3911 0.3684 0.0762 20 496 с 0.3621 0.4727 0.0655 30 802 с 0.1575 0.3487 0.0124 \ / Г / \| 1 Ш Ч ММ! .N1.Гк!.:.;.г 10° Число итераций Рис. 1 График функции (слева), где тонкая линия изображает аналитическое решение, а толстая представляют полученное решение, и график итерации (справа) Г рафик функций Функционал ошибки 1.5 \ \ ...Ж. 4 Г к ¥ 1\ ГМ -1.5 к 1 ! I :::: ■■■■: ^--М-т ■■■■! г-’г: 1 МУ -■! НУ ■ ; ;;; ••••! гМг : : : :: ■■■■: -■! ;..Ш : . : : : : : : : ' ::Л'ГТП Число итераций Рис. 2 График функции (слева), где тонкая линия изображает аналитическое решение, а толстая представляют полученное решение, и график итерации (справа) Г рафик функций Функционал ошибки V \ \ \ 1 1 1 : \! 1 : \. # .1 / V ! ; ; : II I ' : ! ! : ■■;-н.......I...... : : : : N I I I I I I I I I I 4-Н.........I...... I I I I I I : : : I! I I! ! :: :: I 4 I К Значение независимой переменной Число итераций Рис. 3 График функции (слева), где тонкая линия изображает аналитическое решение, а толстая представляют полученное решение, и график итерации (справа) Как видно из результатов экспериментов, при достаточно большом числе элементов возможно получение относительно точного решения. Это говорит о работоспособности идеи использования компактно поддерживаемых радиально-базисных нейронных сетей для решения дифференциальных уравнений в частных производных методом конечных элементов. Выводы Метод использования радиально-базисных нейронных сетей для реализации метода конечных элементов пригоден для аппроксимации решения ДУЧП на одномерном случае. Он более прост в применении, чем стан- дартный метод конечных элементов и бессеточные методы, так как не требует формирование СЛАУ, громоздких матричных преобразований матрицы СЛАУ. Но для его эффективности необходимо разработать более совершенный алгоритм обучения. Кроме того, возможность применения компактно поддерживаемых нейронных сетей для двух- и трехмерных задач ещё не исследована. Работа выполнена по тематическому плану научно-исследовательских работ Пензенского государственного педагогического университета, проводимых по заданию Федерального агентства по образованию. ]]></text>
</doc>
