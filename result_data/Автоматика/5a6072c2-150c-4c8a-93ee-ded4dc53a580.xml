<doc>
  <source auto="true" type="str" verify="true"><![CDATA[https://cyberleninka.ru/article/n/metody-sozdaniya-semanticheskih-metaopisaniy-dokumentov-s-primeneniem-semanticheskih-setey-freymovyh-modeley-i-chastotnyh]]></source>
  <category auto="true" type="str" verify="true"><![CDATA[Автоматика]]></category>
  <author auto="true" type="list" verify="true">
    <item type="str"><![CDATA[Губин Максим Юрьевич]]></item>
    <item type="str"><![CDATA[Разин Владимир Викторович]]></item>
    <item type="str"><![CDATA[Тузовский Анатолий Фёдорович]]></item>
  </author>
  <title auto="true" type="str" verify="true"><![CDATA[Методы создания семантических метаописаний документов с применением семантических сетей, фреймовых моделей и частотных характеристик]]></title>
  <keywords auto="true" type="list" verify="true">
    <item type="str"><![CDATA[Онтология]]></item>
    <item type="str"><![CDATA[семантическая сеть]]></item>
    <item type="str"><![CDATA[Фрейм]]></item>
    <item type="str"><![CDATA[RDF]]></item>
  </keywords>
  <annotation auto="true" type="str" verify="true"><![CDATA[Сформулирован метод создания семантических метаописаний документов с помощью семантических сетей, фреймовых моделей и частотных характеристик анализируемых документов.]]></annotation>
  <text auto="true" type="str" verify="true"><![CDATA[Сформулирован метод создания семантических метаописаний документов с помощью семантических сетей, фреймовых моделей и частотных характеристик анализируемых документов. Ключевые слова: онтология, семантическая сеть, фрейм, RDF. Введение Естественные человеческие языки обладают большой выразительностью и сложностью, существенное влияние на смысл текста в них оказывают контекст и эмоциональная составляющая. Понимание естественного языка включает куда больше, чем разбор предложений на индивидуальные части речи и поиск значений слов в словаре. Оно базируется на обширном фоновом знании о предмете, идиомах, используемых в этой области, а также на способности применять общее контекстуальное знание для понимания недомолвок и неясностей, присущих естественной человеческой речи. Поэтому системы, использующие натуральные языки с гибкостью и общностью, характерными для человеческой речи, лежат за пределами существующих методологий [1]. Однако для определённых условий (когда документ имеет достаточно строгую грамматическую структуру, а следовательно, и содержит достаточно информативную формальную составляющую) данная задача решаема с достаточно высоким качеством распознавания смысла [2]. В этой статье будут описаны условия, выполнение которых необходимо для успешного распознавания, и предлагаемый алгоритм. Постановка задачи Данный алгоритм решает задачу создания метаописаний документов для последующего семантического поиска по ним на данном множестве документов Dj, относящихся к одной предметной области. Под документом Dj в рамках данного исследования будем понимать фрагмент текста на естественном языке. Для реализации семантического поиска по документам необходимо создать достаточно полные семантические метаописания документов Tj. Семантическое метаописание документа строится согласно онтологии предметной области O, представляющей собой набор понятий Cj, связанных между собой отношениями Rj. Также в онтологию предметной области входят экземпляры объектов Ej. Понятия, отношения и экземпляры имеют одну или более текстовых меток Tj. Текстовая метка Tj элемента онтологии - слово либо словосочетание естественного русского языка, соответствующее некоторому элементу онтологии. Для построения базового семантического метаописания на основе текста документа для каждого его предложения Lj формируется семантическая сеть, представляющая собой граф, состоящий из множества вершин Wj и соединяющих их рёбер Lj. Элементарная сеть представляет результат синтаксического анализа и дополнительных семантических трансформаций дерева синтаксических зависимостей между словами в отдельном предложении. Вершинами Wj семантической сети являются сущности, встречающиеся в предложении, а рёбра Lj представляют собой семантические отношения между сущностями. Семантические сети предполагается получать из результатов синтаксического разбора текстов на естественных языках. Задача синтаксического разбора текстов на данный момент в различной степени решена для русского [6, 7] и английского [3-5] языков. Также существуют работы по синтаксическому разбору текстов на французском, норвежском, корейском и греческом [4], а также испанском и японском [4, 5] языках. В данной работе рассматривается частный случай с русским языком. Программный интерфейс большинства существующих семантических анализаторов позволяет получить для каждой сущности набор направленных связей, исходящих от нее к другим сущностям. Направление связи обычно соответствует направлению синтаксического подчинения (для равноправных однородных членов предложения пара одинаковых 228 УПРАВЛЕНИЕ, ВЫЧИСЛИТЕЛЬНАЯ ТЕХНИКА И ИНФОРМАТИКА направленных связей идет в обе стороны). Семантические сети, соответствующие описанным выше критериям, могут быть использованы в разрабатываемом алгоритме с незначительными преобразованиями. Семантическое метаописание - это набор извлечённых из предложений документа RDF-триплетов Tj, представляющих собой кортежи вида <Sj,Pj,Oj>, где Si включен в объединение Cj и Ej, Pj включен в Rj, а Oj включен в объединение Cj и Ej. Также для ускорения актуализации метаданных алгоритмом генерируются частотные характеристики слов в документе - TF- и IDF-терминов [8]. Алгоритм формирования метаданных отдельного документа На вход алгоритма поступает исходный текст файла, а также набор текстовых меток элементов онтологии. Шаги алгоритма: Производится семантический анализ текста. Выходом этого шага является программная структура, содержащая всю требуемую информацию о тексте - слова с номером их начальных символов, смысловые связи между словами, обнаруженные и преобразованные в RDF триплеты (части предложений, соответствующие одному из описанных выше фреймов). Эта программная структура приводится к семантической сети, пригодной для обработки алгоритмом. Подсчитывается количество вхождений слов в текст. При этом не учитываются так называемые «стоп-слова». Стоп-словами являются предлоги, союзы и частицы. Остальные слова нормализуются и количество вхождений подсчитывается именно для нормы слова. Составляется ранговое распределение слов в документе. Слова с одинаковым количеством вхождений объединяются в классы, которые затем нумеруются в порядке убывания количества вхождений слов-членов класса в тексте, начиная с 1 [8]. Производится поиск класса, слова в котором являются значимыми для текста, с наибольшим номером. Все классы, идущие после него, отсеиваются и в дальнейшей работе алгоритма не участвуют. [8] Выставляется первичное значение «веса» слов в документе. Оно равняется Nmax/Nj, где Nmax - количество вхождений слов первого ранга, а Nj - количество вхождений слова tj [8]. Производятся корректировки значений весов для упорядоченных пар слов, входящих в одни и те же триплеты либо предложения. Из множества выделенных из текста RDF-триплетов выбираются: - триплеты, каждая из позиций которых (субъект, предикат и объект) заняты в естественно-языковом представлении вхождением метки (соответственно, субъект и объект - метками понятия либо экземпляра, а предикат - меткой свойства); - триплеты, одна из позиций которых занята вхождением ключевого слова, а две других - вхождением метки, так называемые триплеты-«кандидаты». Выход алгоритма - метаописание документа, в которое входит набор записей вида <Ej,Sj>, где Ej - идентификатор элемента онтологии (так называемый URI - Universal Resource Identifier), а Si - индекс значимости этого элемента для документа. При этом Sj имеет вид Sj = <SjTF, SjIDF,SjC>, где SjTF - коэффициент значимости элемента с точки зрения документа (модифицированный коэффициент TF), SjIDF - коэффициент значимости элемента с точки зрения набора документов (коэффициент IDF); SjC - итоговое значение коэффициента значимости термина. В метаописание также входят все обнаруженные в тексте триплеты, все позиции которых заняты вхождениями меток элементов онтологии. Кроме того, по завершении работы алгоритм генерирует набор вспомогательных записей, уменьшающих время возможной последующей повторной обработки документа. Результаты работы алгоритма - семантические метаописания, которые позволяют реализовать семантический поиск и семантическую навигацию по обработанному множеству текстов. Качество распознавания находится на уровне примерно 60% от распознавания человеком, в зависимости от полноты онтологии предметной области и глубины анализа текста. ]]></text>
</doc>
