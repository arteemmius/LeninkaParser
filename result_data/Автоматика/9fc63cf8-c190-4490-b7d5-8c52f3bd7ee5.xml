<doc>
  <source auto="true" type="str" verify="true"><![CDATA[https://cyberleninka.ru/article/n/analiz-i-perspektivy-razvitiya-infrastruktury-integrirovannoy-informatsionno-vychislitelnoy-seti-irkutskogo-nauchno-obrazovatelnogo]]></source>
  <category auto="true" type="str" verify="true"><![CDATA[Автоматика]]></category>
  <author auto="true" type="list" verify="true">
    <item type="str"><![CDATA[Бычков И. В.]]></item>
    <item type="str"><![CDATA[Маджара Т. И.]]></item>
    <item type="str"><![CDATA[Новопашин А. П.]]></item>
    <item type="str"><![CDATA[Опарин Г. А.]]></item>
    <item type="str"><![CDATA[Ружников Г. М.]]></item>
  </author>
  <title auto="true" type="str" verify="true"><![CDATA[Анализ и перспективы развития инфраструктуры интегрированной информационно-вычислительной сети Иркутского научно-образовательного комплекса]]></title>
  <keywords auto="true" type="list" verify="true">
    <item type="str"><![CDATA[ИНФОРМАЦИОННО-ВЫЧИСЛИТЕЛЬНЫЕ И ТЕЛЕКОММУНИКАЦИОННЫЕ РЕСУРСЫ]]></item>
    <item type="str"><![CDATA[КОРПОРАТИВНЫЕ СЕТИ И МАРШРУТИЗАЦИЯ]]></item>
    <item type="str"><![CDATA[IP-ТЕЛЕФОНИЯ]]></item>
    <item type="str"><![CDATA[ВЫСОКОПРОИЗВОДИТЕЛЬНЫЕ ВЫЧИСЛИТЕЛЬНЫЕ СИСТЕМЫ]]></item>
    <item type="str"><![CDATA[ПРОБЛЕМНО-ОРИЕНТИРОВАННЫЕ БАЗЫ ДАННЫХ]]></item>
  </keywords>
  <annotation auto="true" type="str" verify="true"><![CDATA[В статье изложены этапы создания и перспективы развития информационно-вычислительной и телекоммуникационной инфраструктуры Иркутского научно-образовательного комплекса.]]></annotation>
  <text auto="true" type="str" verify="true"><![CDATA[В статье изложены этапы создания и перспективы развития информационно-вычислительной и телекоммуникационной инфраструктуры Иркутского научно-образовательного комплекса. Ключевые слова: информационно-вычислительные и телекоммуникационные ресурсы, корпоративные сети и маршрутизация, IP-телефония, высокопроизводительные вычислительные системы, проблемно-ориентированные базы данных. Введение В Байкальском регионе накоплена, постоянно обновляется и актуализируется уникальная информация, относящаяся к различным отраслям науки и производства, природному комплексу, социально-экономическому и экологическому состоянию территорий. Отмечается существенный рост потребностей со стороны науки и образования в доступных информационно-вычислительных ресурсах для проведения фундаментальных и прикладных исследований. Это приводит к необходимости интеграции (в том числе с использованием грид-технологий) пространственно распределенных хранилищ разнородных данных и вычислительных мощностей, организации коллективного доступа к ним. Основная задача созданной региональной инфраструктуры - поддержка научно-образовательной среды Байкальского региона путем объединения корпоративных сетей, создания на их основе информационно-телекоммуникационных и вычислительных ресурсов коллективного пользования и средств управления ими. Цели и этапы создания информационно-вычислительной и телекоммуникационной инфраструктуры Отсутствие единства в выборе информационных технологий, разобщенность накопленной научной информации как по способу, месту хранения, так и по форме представления, сложность принятия управленческих решений при организации междисциплинарных исследований, необходимость четкой координации работ по интеграционным проектам - все это в комплексе явилось предпосылкой к созданию общего информационного пространства, основой для которого стала Интегрированная информационно-вычислительная сеть Иркутского научно-образовательного комплекса (ИИВС ИрНОК). В 1994 г. Институтом динамики систем и теории управления (ИДСТУ) СО РАН разработан системный проект ИИВС ИрНОК и была начата его реализация [Vassilyev, Stupin, 1998]. Проект преследовал следующие цели: - объединение корпоративных информационно-вычислительных ресурсов научных учреждений Иркутского научного центра СО РАН и вузов города Иркутска в единую сеть высокоскоростными каналами связи; ISSN 1818-7900. Вестник НГУ. Серия: Информационные технологии. 2008. Том 6, выпуск 1 © И. В. Бычков, Т. И. Маджара, А. П. Новопашин, Г. А. Опарин, Г. М. Ружников, 2008 - поддержка и расширение доступа в Интернет. Для реализации проекта были привлечены финансовые средства Министерства науки и технологий РФ, РФФИ, СО РАН, внебюджетные средства ИДСТУ СО РАН, других институтов ИНЦ СО РАН, а также некоторых организаций, впоследствии вошедших в ИрНОК. Как транспортная инфраструктура, построенная на основе многомодовых волоконнооптических линий связи (ВОЛС), ИИВС была введена в эксплуатацию в 1994 г., имея две выделенные опорные точки в ИДСТУ СО РАН и ИСЗФ СО РАН. К моменту своего запуска ИИВС ИрНОК включала один внешний канал пропускной способностью 128 Кбит/с с точкой доступа на узле ОАО «Ростелеком» с дальнейшим выходом в глобальную сеть по инфраструктуре RBNet. По мере роста требований пользователей Сети внешний канал связи постепенно расширялся. Следующий важный этап развития ИИВС ИрНОК стартовал в 2002 г. с началом работ по проекту «Создание интегрированной информационно-вычислительной сети (с высокоскоростными каналами связи) научных и образовательных учреждений Байкальского региона (Республика Бурятия, Иркутская и Читинская области) в рамках Федеральной целевой программы «Интеграция науки и высшего образования России на 2002-2006 годы». Головным исполнителем проекта выступил ИДСТУ СО РАН, а соисполнителями - Бурятский научный центр СО РАН, Бурятский государственный университет, Иркутский государственный технический университет (ИрГТУ) и Читинский государственный технический университет. Цели этого этапа стали более крупными и ориентированными на создание информационно-телекоммуникационной инфраструктуры Байкальского региона: - объединение корпоративных информационно-вычислительных ресурсов научных и образовательных учреждений Байкальского региона в единую сеть высокоскоростными каналами связи; - поддержка и расширение доступа в Интернет; - использование телеконференций в научном и учебном процессе; - создание вычислительного грид-сегмента регионального уровня на базе суперкомпьютерного центра (СКЦ) Иркутского научного центра (ИНЦ) СО РАН; - разработка так называемого промежуточного программного обеспечения для организации распределенных вычислений в рамках ИрНОК. Проект реализовывался при организационной и финансовой поддержке Целевой программы «Информационно-телекоммуникационные ресурсы СО РАН» и внешнего оператора сети Института вычислительных технологий СО РАН. Канал, пропускной способностью 2 Мбит/c, связавший ИИВС ИрНОК с Сетью передачи данных СО РАН, был предоставлен ЗАО «Компания Транстелеком», выигравшим тендер, объявленный Российской академией наук. При выполнении проекта были проложены дополнительные ВОЛС между сетями организаций - участников проекта, а также до точек присутствия сети ЗАО «Компания Транстелеком» в городах Иркутск, Улан-Удэ, Чита и существенно модернизирован состав магистрального оборудования Сети. В период с 2002 по 2006 г. ИИВС ИрНОК развивалась в следующих направлениях: - открыт Центр управления сетью, оснащенный современным компьютерным оборудованием, с автономными системами сигнализации, электроснабжения и кондиционирования для узла связи и СКЦ ИНЦ СО РАН; - полностью реорганизован оптический кросс узла: старые клеевые соединения, находившиеся в эксплуатации с 1994 г., заменены современными сварными, оптический кросс перенесен в специальное изолированное помещение; - сегменты Сети с пропускной способностью до 10 Мбит/с расширены до 100 Мбит/с; - в опорных узлах проведена замена устаревших коммутаторов Bay Stack 350F на современные управляемые Cisco Catalyst 3550, благодаря чему улучшилась управляемость Сети, повышен уровень информационной безопасности, реализованы новые возможности для мониторинга и анализа информационных потоков; - выполнена модернизация ядра Сети, в которое добавлен второй маршрутизатор для более эффективного управления распределением трафика между организациями; - проведена перенумерация Сети для полного соответствия требованиям СПД СО РАН; - перестроена система доставки сообщений электронной почты; - все почтовые домены учреждений ИНЦ, исторически находившиеся в зоне ответственности ОАО «Деловая Сеть - Иркутск», перешли под управление системных администраторов службы поддержки и развития ИИВС ИрНОК; - разработаны и внедрены методы защиты от несанкционированных почтовых рассылок; - существенно расширены внешние каналы доступа, достигшие в 2005 г. суммарной пропускной способности в 14 Мбит/с. Построенная по корпоративному принципу сеть передачи данных СО РАН (СПД СО РАН) и присоединенная к ней в 2002 г. ИИВС ИрНОК, кроме собственно передачи данных, стали способны обеспечивать телефонную, а также видеоконференц-связь между орга-низациями-участниками проекта. В 2005 г. в ИДСТУ СО РАН разработан проект по созданию на базе существующей инфраструктуры ИИВС корпоративной телефонной сети (КТС) ИНЦ СО РАН, приобретено необходимое оборудование и проведены первые эксперименты. Новый этап развития ИИВС ИрНОК ознаменовался включением в 2006 г. в нее корпоративной сети Бурятского научного центра (Улан-Удэ), обеспечением для нее транзита в СПД СО РАН и далее в мировые сети. ИИВС приобрела статус регионального узла. Тогда же началась работа по модернизации кабельной инфраструктуры. На участках магистрали ИДСТУ СО РАН -ИСЗФ СО РАН и ИСЗФ СО РАН - ИрГТУ увеличена пропускная способность до 1 Гбит/c. Введена в эксплуатацию первая очередь КТС ИНЦ, выполнено ее присоединение к КТС СО РАН (Новосибирск), открыты первые международные телефонные направления на Новосибирск, Якутск, Тюмень. В 2007 г. введена в эксплуатацию система видеоконференц-связи. Проведены первые научные семинары с участием представителей нескольких городов, организованы дистанционные чтения лекций. К настоящему времени ИИВС ИрНОК, являясь составной частью межрегиональной инфраструктуры, объединяет все институты ИНЦ СО РАН, большую часть вузов города, а также ряд учреждений Восточно-Сибирского научного центра (ВСНЦ) РАМН, а именно: Президиум ИНЦ СО РАН; Институт динамики систем и теории управления (ИДСТУ) СО РАН; Институт земной коры (ИЗК) СО РАН; Институт систем энергетики (ИСЭМ) СО РАН; Институт химии (ИХ) СО РАН; Сибирский институт физиологии и биохимии растений (СИФИБР) СО РАН; Иркутский филиал института лазерной физики (ИрФИЛФ) СО РАН; Институт геохимии (ИГХ) СО РАН; Институт географии (ИГ) СО РАН; Институт солнечно-земной физики (ИСЗФ) СО РАН; Лимнологический институт (ЛИН) СО РАН; Байкальский музей (БМ) СО РАН; Восточно-сибирский институт (ВСИ) МВД; Иркутский государственный технический университет (ИрГТУ); Иркутский государственный университет путей сообщения (ИрГУПС); Иркутский государственный педагогический университет (ИГПУ); Иркутский государственный университет (ИГУ); Восточно-сибирский научный центр (ВСНЦ) СО РАМН; Байкальский институт бизнеса, менеджмента и маркетинга (БИБ ММ) ИГУ. Сейчас ИИВС ИрНОК выполняет следующие функции: - информационно-вычислительное обеспечение при проведении межинститутских и междисциплинарных научных исследований по фундаментальным и прикладным направлениям; - обеспечение организаций ИрНОК информационно-телекоммуникационными услугами, включая построение в рамках ИНЦ телефонной сети на собственных каналах связи с выходом в КТС СО РАН, а также проведение видеоконференций; - концентрация аппаратных средств и программного обеспечения с целью одновременного использования дорогостоящих вычислительных, дисковых, коммуникационных и других ресурсов; - поддержка принятия организационных и управленческих решений, контроль за их исполнением; - обеспечение возможности коллективного доступа к электронным библиотекам. Кроме традиционных сетевых ресурсов (электронных библиотек, web-сайтов институтов и личных web-страниц сотрудников), ИИВС ИрНОК объединяет уникальные информационные ресурсы, связанные с исследованиями озера Байкал и природы Байкальского региона в целом: базы данных флоры и фауны (ЛИН СО РАН, СИФИБР СО РАН), геохимии окружающей среды и осадочных бассейнов (ИГХ СО РАН), ландшафтов и геосистем (ИГ СО РАН); электронные геологические, природно-ресурсные карты; данные дистанционного зондирования территории Восточной Сибири (ИДСТУ СО РАН, ИГ СО РАН, ИСЗФ СО РАН); геофизическая, геохимическая мониторинговая информация (ИЗК СО РАН, ИГХ СО РАН); показатели социально-экономического развития региона (Отдел региональных экономических и социальных проблем ИНЦ СО РАН, ИДСТУ СО РАН) и многие другие. Для крупнейших вузов Иркутска ИИВС предоставляет возможности для организации учебных компьютерных классов с доступом в Интернет, а также реализации программ дистанционного образования. Силами ИДСТУ СО РАН создана служба технической поддержки и развития ИИВС ИрНОК, которая осуществляет внедрение передовых телекоммуникационных технологий, решает задачи информационной безопасности, мониторинга и анализа ИИВС. Развитая материально-техническая база и телекоммуникационная инфраструктура, большой объем информационно-вычислительных и научно-образовательных ресурсов, обеспеченность квалифицированными кадрами, а также удачное географическое расположение способствуют созданию на базе ИИВС ИрНОК крупного инфо-коммуникационного и вычислительного центра для научных и образовательных учреждений Байкальского региона. ИИВС ИрНОК как часть корпоративной академической сети хранения, обработки, пере- Одномодовая волоконно-оптическая = ==' Витая пара UTP cat. 5, 100 Мбит/сек. линия связи (ВОЛС) Многомодовая ВОЛС, 100 Mбит/сек.) — ■ — ■ — ■ — . — . Медная гараАВ^ 8 Mбит/сек. дачи данных и доступа к вычислительным ресурсам СО РАН обеспечивает своим абонентам (пользователям) полноценную связь с российскими (RUNet) и зарубежными глобальными сетями. Архитектура ИИВС В настоящее время ИИВС работает на базе оптоволоконной структуры, интегрированной в гигабитное кольцо города Иркутска. Опорные узлы ИИВС ИрНОК расположены в ИДСТУ СО РАН, ИСЗФ СО РАН и на телекоммуникационной площадке «Байкал-Транстелеком». Основными технологиями передачи данных в Сети на канальном уровне являются FastEthemet и GigabitEthemet, однако для некоторых участников (ввиду невозможности использования данных технологий из-за удаленности от крупных опорных узлов) используются ADSL-соединения. ИГУ и ИГПУ включены непосредственно в гигабитное кольцо Иркутска на узлах ТЦМС-12 и «Иркутскэнерго» соответственно. Подключение двух названных организаций с использованием технологий VLAN и IP VPN (MPLS/VPN) позволяет терминировать их транспортные сети непосредственно на внутреннем маршрутизаторе ИИВС. В целях осуществления гибкой динамической маршрутизации по протоколу BGP [Хе-леби и др., 2001] сети ИрНОК объединены в автономную систему, которой присвоен номер AS8506. Структурная схема Сети представлена на рис. 1. Маршрутизацию сетей внутри ИИВС и за ее пределы осуществляют Cisco 7301, 7120, Catalyst 3550 при помощи протокола BGP c использованием «частных» автономных систем. На магистральных коммутаторах Сети функционируют системы защиты от подделки mac-адресов, arp-спуфинга, включения в сеть посторонних пользователей, системы контроля за прохождением пакетов, что позволяет избежать излишней нагрузки на маршрутизатор в случае реализации атак. В ИИВС ИрНОК активно используется стандарт IEEE 802.1q, что позволяет строить под некоторые виды задач виртуальные сети достаточно сложной конфигурации. На телекоммуникационном узле ИДСТУ СО РАН расположен сервер телематических служб на платформе Fujitsu Siemens Primergy P250. Сервер работает под управлением операционной системы FreeBSD, является резервным почтовым сервером для серверов всех институтов. Кроме этого, на его базе организованы серверы DNS, WEB, FTP и др. Кабельная инфраструктура Кабельная инфраструктура ИИВС представлена на рис. 2. Узлы связи, отмеченные черным цветом, непосредственно включены в гигабитное кольцо Иркутска. Опорная сеть ИрНОК представлена на рисунке следующими кабельными трассами: ИДСТУ СО РАН - ИСЗФ СО РАН (одно-мод, канализация «Сибирьтелеком»); ИДСТУ СО РАН - Южные электрические сети (одномод, канализация «Сибирьтелеком»); ИСЗФ СО РАН - ВСИ МВД - ИрГТУ -ИрГУПС - ТЦМС-12 - »Транстелеком» (од-номод, канализация «Сибирьтелеком»); ИДСТУ СО РАН - ИЗК СО РАН - ИХ СО РАН - ИГХ СО РАН (многомод, канализация ИДСТУ СО РАН); ИДСТУ СО РАН - ИСЭМ СО РАН -ИрФИЛФ СО РАН (многомод, канализация ИДСТУ СО РАН); ИДСТУ СО РАН - СИФИБР СО РАН (многомод, «воздушка»); ИДСТУ СО РАН - Президиум ИНЦ СО РАН (многомод, подвал ИДСТУ СО РАН). Рис. 2. Кабельная инфраструктура ИИВС ИрНОК, интегрированная в гигабитное кольцо Иркутска Использование в ИИВС топологии колец обеспечило устойчивую работу Сети при повреждениях кабеля в том или ином сегменте. За последние годы требования к пропускной способности магистрали и внешних каналов ИИВС ИрНОК существенно возросли. Это связано, прежде всего, с увеличением парка компьютеров и появлением ресурсоемких приложений и технологий, таких как различные системы мониторинга, ГИС-системы, высокопроизводительные вычисления. В последнее время Сеть столкнулась с проблемой обеспечения требуемого качества обслуживания (QoS) в связи с вводом в эксплуатацию систем IP-телефонии [Гольдштейн и др., 2001] и видеоконференц-связи. Таким образом, одним из приоритетных направлений развития кабельной инфраструктуры является замена старых, выработавших свой технологический ресурс многомодовых ВОЛС, на новые - одномодовые. В 2005 г. в Иркутске проведены проектно-изыскательские работы в рамках проекта по строительству высокоскоростной транспортной оптоволоконной сети кольцевой топологии c пропускной способностью 300 Гбит/с. Присоединение ИИВС к данному кольцу позволит перевести Сеть на новый уровень взаимодействия с информационными пространствами города и области. В 2006 г. для Байкальского музея СО РАН, расположенного в пос. Листвянка, создана ADSL-линия, которая позволила решить комплексную проблему связи - обеспечение доступа в ИИВС ИрНОК в совокупности с телефонизацией. До конца 2007 г. будет полностью завершена модернизация оптической трассы ИДСТУ СО РАН - ИЗК СО РАН - ИХ СО РАН - ИГХ СО РАН с ее переходом на использование одномодовых кабелей. Канальная инфраструктура Внешние каналы Сети с точками входа на узле связи ЗАО «Байкал-Транстелеком» имеют общую пропускную способность 14 Мбит/с (рис. 3). Соединение с сетью Новосибирского научного центра СО РАН осуществлено посредством трех независимых каналов (FastEthemet - 10 Мбит/с, 2хИ.703 - 2 х 2 Мбит/с). ИИВС также имеет пиринговые соединения с крупнейшим региональным интернет-сервис провайдером ОАО «Деловая Сеть - Иркутск», а также с ведущим системным интегратором ЗАО «РЦСИ Сиброн». Магистраль Сети имеет пропускную способность 1 Гбит/c. Суммарный суточный внешний входящий трафик ИИВС ИрНОК колеблется в пределах 75-95 Гбайт в зависимости от дня недели. Перспективы развития канальной инфраструктуры Сети состоят в дальнейшем расшире- ЛВС БМ СО РАН ВСНЦ СО РАМН БайкалТрансТелеком 10Мбит/с. Новосибирск (FastEthernet) 2 Мбит/с. Новосибирск 2 Мбит/с. Новосибирск 2 Мбит/с. Улан-Удэ (G.704) о о нии существующих внешних каналов связи, а также в модернизации внутренней инфраструктуры ИИВС. Корпоративная телефонная сеть ИНЦ СО РАН Построение корпоративной телефонной сети институтов (КТС) ИНЦ - одно из приоритетных направлений по созданию единого информационного пространства ИНЦ СО РАН. В рамках программы «Информационно-телекоммуникационные ресурсы СО РАН» ИДСТУ СО РАН координирует развитие КТС ИНЦ СО РАН и IP-телефонии, осуществляет перевод телефонных сетей под управление АТС Avaya Definity c активным использованием технологии VoIP на телекоммуникационной инфраструктуре ИИВС ИрНОК. К настоящему времени проведены следующие работы: - приобретена стартовая номерная емкость (200 номеров, «Сибирьтелеком»); - на узле связи ИДСТУ СО РАН смонтирована и настроена новая АТС; - организовано присоединение новой АТС к телефонной сети общего пользования цифровым каналом Е1; - установлен сервер доступа Cisco AS5350 в качестве VoIP-шлюза и сервера цифрового коммутируемого доступа; - часть абонентов телефонных сетей ИДСТУ СО РАН, Президиума ИНЦ СО РАН и ИСЭМ СО РАН переведены на обслуживание новой станцией; - через КТС СО РАН организованы 3 междугородних направления - Новосибирск, Якутск, Тюмень. В своем настоящем виде КТС ИНЦ представлена на рис. 4. В дальнейшем планируется поэтапное расширение телефонной сети путем присоединения к ней абонентов организаций ИрНОК. Присоединение может осуществляться разными способами: с помощью непосредственного объединения АТС организаций между собой каналами Е1, с использованием VoIP-шлюзов, путем построения сегментов на базе протокола SIP [Гольдштейн и др., 2005] и т. д. К концу 2007 г. к КТС ИНЦ планируется полностью подключить абонентов телефонных сетей ИСЗФ СО РАН (путем его присоединения каналом E1) и БФГС СО РАН (с помощью дополнительного малого VoIP-шлюза). Системы мониторинга и анализа ТС ИДСТУ VoIP-шлюзы Г| БМ СО РАН, ''ИСЭМ СО РАН, Президиум ИНЦ, ИрГТУ В 2004 г. службой технической поддержки ИИВС ИрНОК разработана и внедрена система мониторинга трафика, потребляемого каждой организацией, входящей в ИрНОК. Подсчет ведется в реальном времени с занесением суммарных значений в базу данных 1 раз в час. Данная система позволяет не только определить количественные характеристики потока информации, но и разбить его с определенной долей условности на классы: http, ftp, smtp, pop3 и т. д . Система мониторинга использует технологию Cisco NetFlow. При прохождении пакета (сессии) через любой из маршрутизаторов сети им генерируется, а затем отправляется серверу статистики UDP-сообщение, в котором указываются характеристики пакета. UDP-сообщение, попадая на сервер статистики, согласно заданному администратором набору правил и фильтров, ориентированных на конкретную организацию и определенный вид трафика, пополняет соответствующий счетчик. Снятие статистики, изменение набора правил и фильтров, подключение / отключение организаций к системе подсчета трафика осуществляются параллельно с работой коллектора, что не требует приостановки обработки потока UDP-сообщений. На сетевых устройствах, обеспечивающих подключение и маршрутизацию локальных вычислительных сетей организаций, функционирует протокол SNMP, позволяющий в реальном режиме времени получать информацию о входящем / исходящем трафике на каждом порту, определять наличие ошибок при передаче данных и многое другое. Информация, получаемая по данному протоколу, обрабатывается системой MRTG и затем в виде графиков отображается на сайте сервера статистики. В настоящий момент служба технической поддержки ведет работы по переносу системы анализа трафика на новую программную платформу под названием RRD, которая является развитием системы MRTG. Используемая в настоящее время система мониторинга и анализа трафика предоставляет вниманию системных администраторов главным образом количественные характеристики информационных потоков. В то же время ввиду частого использования телекоммуникационных ресурсов сети не по назначению весьма актуальной является проблема качественного анализа и регулирования трафика. Если раньше можно было однозначно классифицировать трафик по номеру порта, то сегодня при бурном развитии пиринговых (P2P) сетей бывает очень сложно отделить http-трафик, передаваемый научной библиотекой, от потока, содержащего фрагменты видеофильма, передаваемого по тому же 80-му TCP-порту пиринговой системой. Ситуация осложнена еще и тем, что алгоритм выявления такого трафика в реальном режиме времени в высокоскоростном потоке должен быть достаточно производительным. В 2007 г. была создана и успешно протестирована система, способная выделить трафик некоторых популярных пиринговых клиентов (bittorrent, eDonkey). По каждому участнику ИИВС ИрНОК получены цифры, характеризующие степень использования ими P2P-приложений. Система способна работать в тандеме с граничным маршрутизатором Сети в реальном режиме времени, позволяя «на лету» устанавливать ограничения по полосе пропускания для данного вида трафика. Борьба с несанкционированными почтовыми рассылками Для ИИВС ИрНОК проблема несанкционированных почтовых рассылок весьма актуальна. Комплексные системы защиты от спама, разработанные в ИДСТУ СО РАН и ИСЗФ СО РАН, зарекомендовали себя как эффективное средство борьбы с нежелательной корреспонденцией. При внедрении методов предотвращения несанкционированных почтовых рассылок главная задача состоит в распознавании таковых лишь на начальных этапах почтовых сессий (HELO, MAIL FROM и RCPT TO) протокола SMTP. Анализ содержания писем (этап DATA) не может дать нужный эффект, так как тело письма до начала анализа должно целиком поступить на сервер, что уже само по себе наносит материальный ущерб организации (плата за трафик). Принцип работы спам-фильтров на этапе DATA должен заключаться в том, чтобы выявить определенные параметры почтовых сообщений для следующего их использования на этапах, предшествующих DATA. При всем многообразии методов, применяемых спамерами для маскировки своих сообщений под легальные, наиболее эффективными оказались спам-фильтры, использующие следующие свойства несанкционированных массовых рассылок. Свойства, присущие хостам-источникам массовых рассылок: - уход от использования постоянных IP-адресов с «правильными» обратными зонами (PTR) вследствие быстрого попадания их в мировые DNSBL-листы, вместо этого - использование IP-адреса c легко узнаваемыми «динамическими» обратными зонами либо адреса с полным отсутствием таковых; - регулярная смена почтовых зон адреса отправителя при постоянной форме MX-записи в DNS. Свойства, характерные для программного обеспечения массовых рассылок: - несоблюдение некоторых стандартов RFC на всех этапах почтовой сессии; - попытки использования легальных строк приветствия с хостов, PTR-записи для IP-адресов которых абсолютно не соответствуют заявленной строке приветствия; - неустойчивость к кратковременным потерям связи. Кроме описанных свойств нежелательных почтовых рассылок, системы защиты почты ИИВС ИрНОК учитывают и другие признаки, выявляемые различными способами. Отслеживание перечисленных свойств на первых трех этапах почтовой сессии привело к 75-80-процентному сокращению объема несанкционированной почтовой корреспонденции и крайне незначительному проценту потерь официальной почты (менее 0,1 %). При срабатывании спам-фильтра в системе предусмотрена возможность уведомления об этом отправителя с указанием специального адреса, на который можно направить сообщение о ложном срабатывании. На основании таких сообщений системным администратором производится корректировка конфигурации фильтров. Суперкомпьютерный центр С начала 2005 г. при ИДСТУ СО РАН функционирует суперкомпьютерный центр коллективного пользования 1 [Новопашин, Сидоров, 2005]. Развитие материально-технической базы СКЦ осуществляется в рамках программы «Суперкомпьютер СО РАН». Главным вычислительным ресурсом центра в настоящее время является кластер МВС-1000 с пиковой производительностью 170 GFlops, созданный при участии ИПМ им. Келдыша РАН и ФГУП «Квант» (Москва). Кластер имеет в своем составе 16 двухпроцессорных вычислительных узлов, связанных между собой интерконнек-том Myrinet (для внутрипрограммных обменов) и GigabitEthernet (для выполнения сервисных операций). К МВС организован удаленный доступ пользователей по протоколу ssh, выполнение заданий осуществляется в пакетном режиме. С 2006 г. в СКЦ ведется создание второго мощного вычислителя кластерного типа, который в итоге должен многократно превзойти своего предшественника по рабочим характеристикам. Кластер строится на базе современных серверных платформ Intel S5000 и многоядерных 64-разрядных процессоров Intel Xeon Quad-Core Clovertown. Суммарная пиковая производительность двадцати вычислительных узлов (40 процессоров, 160 ядер) составит 750 GFlops. 1 http://mvs.icc.ru Кластеры (рис. 5) работают под управлением операционной системы Gentoo Linux и снабжены стандартным набором средств для создания, отладки и запуска параллельных программ, включая компиляторы языков С/С++ и Fortran, коммуникационные интерфейсы (MPI и PVM), параллельные предметные библиотеки (ScaLAPACK, MKL, ATLAS, FFT, PETSc), системы параллельного программирования (DVM и HPF-adaptor), средства мониторинга и управления процессом прохождения параллельных задач. Кроме того, имеется возможность установки коммерческих прикладных пакетов, специально разработанных для параллельных вычислительных платформ и предназначенных для решения задач инженерного анализа, прочности, теплофизики, деформации, упругости, пластичности, электромагнетизма (ANSYS, LS-Dyna, ABAQUS), аэро- и гидродинамики, механики жидкостей и газов, горения и детонации (CFX, Fluent, FlowVision), акустического анализа (LMS Acoustics), квантовохимических расчетов (HyperChem). С использованием вышеописанного оборудования в СКЦ сегодня решается целый ряд научно-исследовательских задач, из которых можно выделить следующие: - разработка параллельных алгоритмов для решения проблем динамической оптимизации управляемых систем [Сидоров и др., 2006]; - реализация кластерного подхода к решению задачи выполнимости (или SAT-задачи) [Заикин и др., 2007]; - создание параллельной версии решателя больших разреженных систем булевых уравнений [Опарин и др., 2006; Опарин и др., 2007]; - разработка инструментальных средств крупноблочного синтеза параллельных программ для вычислительных кластеров [Опарин, Федосов и др., 2007; Опарин, Новопашин и др., 2006а; 2006б]; - разработка параллельного алгоритма глобального поиска равновесных ситуаций в биматричных играх [Васильев и др., 2007]; - численное моделирование точечных дефектов в кристаллах щелочных и щелочноземельных фторидов с применением методов квантовой химии твердого тела [Mysovsky et al., 2006; Myasnikova et al., 2006]. Приоритетными задачами СКЦ являются: 1) создание и сопровождение высокопроизводительных установок коллективного пользования, ориентированных, в первую очередь, на выполнение сложных расчетов при проведении фундаментальных и прикладных исследований в организациях ИрНОК; 2) популяризация в научно-образовательной среде Байкальского региона технологий организации параллельных и распределенных вычислений с целью массового внедрения последних в практику расчетных работ, привлечение на кластерные установки новых пользователей, повышение уровня их подготовки (методическое обеспечение, консультации, семинары, спецкурсы); 3) разработка высокоуровневых, ориентированных на широкий круг специалистов средств программирования параллельных и распределенных вычислительных систем. Основные направления развития ИИВС Дальнейшее развитие ИИВС ИрНОК непосредственно связано с приданием ей нового качества - мультисервисности. В этом направлении уже началась работа по расширению систем корпоративной традиционной и 1Р-телефонии с широким набором сервисных функций, а также активному внедрению систем видеоконференц-связи. Такая задача, в свою очередь, требует серьезной модернизации сетевой инфраструктуры - приобретения дополнительного оборудования, замены старых многомодовых ВОЛС на одномод, перехода к использованию на периферийных участках Сети каналов с пропускной способностью 1 Гбит/с, а также расширения внешних каналов связи. Особая роль в создании мультисервисной Сети отводится организации эффективных средств мониторинга и управления. Совершенствование информационно-вычислительной составляющей ИИВС ИрНОК осуществляется в следующих направлениях: сборка, отладка и ввод в штатную эксплуатацию вычислительного кластера СКЦ с пиковой производительностью 750 GFlops, объединение кластеров СКЦ в единый грид-сегмент ИНЦ СО РАН с целью их совместного использования для решения ресурсоемких междисциплинарных задач, создание единого сервера баз данных институтов ИНЦ СО РАН. В связи с увеличением в институтах ИНЦ СО РАН объемов тематических данных, необходимых для проведения междисциплинарных исследований, актуальным направлением развития ИИВС ИрНОК видится создание современной системы хранения данных на основе, например, SAN-архитектуры [Judd, Kruger, 2005]. Заключение В Иркутском научном центре СО РАН создана Интегрированная информационновычислительная сеть как часть корпоративной академической сети хранения, обработки, передачи данных и медиа-информации, а также доступа к вычислительным ресурсам СО РАН. Развитие ИИВС ИрНОК позволяет решить задачу формирования региональной инфраструктуры информационно-вычислительных и телекоммуникационных ресурсов научнообразовательного комплекса Байкальского региона. Создание и эксплуатация ИИВС ИрНОК осуществляется при организационной и финансовой поддержке программ «Информационно-телекоммуникационные ресурсы СО РАН» и «Суперкомпьютер СО РАН». ]]></text>
</doc>
